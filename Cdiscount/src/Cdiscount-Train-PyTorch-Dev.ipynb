{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model, assemble_model_with_classifier\n",
    "from trainer.trainer import get_trainer\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# redirect print to file\n",
    "# import sys\n",
    "# sys.stdout = open(\"PyTorch-resnet34-log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'train_batch_size': 128, 'val_batch_size': 128,\n",
    "    'arch': 'vgg19_bn', 'pretrained': True,\n",
    "    'optimizer': 'Adam', 'learning_rate': 1e-4, 'decay_lr_freq': 4e4, 'weight_decay': 1e-5,\n",
    "    'resume': None,\n",
    "    'start_epoch': 0, 'epochs': 10,\n",
    "    'print_freq': 10, 'validate_freq': 7e4, 'save_freq': 1e3,\n",
    "    'best_val_prec1': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n",
      "=> using pre-trained model 'vgg19_bn'\n",
      "DataParallel (\n",
      "  (module): AssembledModel (\n",
      "    (model): Sequential (\n",
      "      (0): Sequential (\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): ReLU (inplace)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (5): ReLU (inplace)\n",
      "        (6): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (9): ReLU (inplace)\n",
      "        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (12): ReLU (inplace)\n",
      "        (13): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (16): ReLU (inplace)\n",
      "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (19): ReLU (inplace)\n",
      "        (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (22): ReLU (inplace)\n",
      "        (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (25): ReLU (inplace)\n",
      "        (26): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (29): ReLU (inplace)\n",
      "        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (32): ReLU (inplace)\n",
      "        (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (35): ReLU (inplace)\n",
      "        (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (38): ReLU (inplace)\n",
      "        (39): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (42): ReLU (inplace)\n",
      "        (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (45): ReLU (inplace)\n",
      "        (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (48): ReLU (inplace)\n",
      "        (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (51): ReLU (inplace)\n",
      "        (52): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential (\n",
      "      (0): Linear (12800 -> 5270)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "start training\n",
      "Epoch: [0][0/77344]\tTime 35.685 (35.685)\tData 4.277 (4.277)\tLoss 8.6035 (8.6035)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][10/77344]\tTime 2.671 (5.595)\tData 0.010 (0.397)\tLoss 7.6053 (8.2361)\tPrec@1 3.125 (2.344)\tPrec@5 10.938 (6.037)\n",
      "Epoch: [0][20/77344]\tTime 2.709 (4.217)\tData 0.010 (0.212)\tLoss 6.7605 (7.7217)\tPrec@1 8.594 (4.353)\tPrec@5 17.969 (8.891)\n",
      "Epoch: [0][30/77344]\tTime 2.686 (3.727)\tData 0.008 (0.147)\tLoss 6.7721 (7.4286)\tPrec@1 9.375 (6.023)\tPrec@5 18.750 (11.820)\n",
      "Epoch: [0][40/77344]\tTime 2.727 (3.479)\tData 0.009 (0.113)\tLoss 6.3663 (7.2166)\tPrec@1 14.844 (7.393)\tPrec@5 26.562 (14.234)\n",
      "Epoch: [0][50/77344]\tTime 2.719 (3.328)\tData 0.008 (0.093)\tLoss 6.1087 (7.0039)\tPrec@1 14.844 (9.237)\tPrec@5 28.906 (17.080)\n",
      "Epoch: [0][60/77344]\tTime 2.725 (3.226)\tData 0.008 (0.079)\tLoss 5.8400 (6.8205)\tPrec@1 19.531 (10.733)\tPrec@5 32.812 (19.531)\n",
      "Epoch: [0][70/77344]\tTime 2.699 (3.152)\tData 0.010 (0.069)\tLoss 5.7923 (6.6766)\tPrec@1 15.625 (11.972)\tPrec@5 27.344 (21.248)\n",
      "Epoch: [0][80/77344]\tTime 2.705 (3.097)\tData 0.008 (0.062)\tLoss 5.1909 (6.5454)\tPrec@1 19.531 (12.886)\tPrec@5 39.062 (22.907)\n",
      "Epoch: [0][90/77344]\tTime 2.706 (3.054)\tData 0.007 (0.056)\tLoss 5.7208 (6.4271)\tPrec@1 20.312 (13.779)\tPrec@5 35.938 (24.365)\n",
      "Epoch: [0][100/77344]\tTime 2.706 (3.020)\tData 0.007 (0.051)\tLoss 5.1515 (6.3301)\tPrec@1 26.562 (14.542)\tPrec@5 39.062 (25.526)\n",
      "Epoch: [0][110/77344]\tTime 2.701 (2.991)\tData 0.013 (0.048)\tLoss 5.2672 (6.2490)\tPrec@1 24.219 (15.139)\tPrec@5 40.625 (26.591)\n",
      "Epoch: [0][120/77344]\tTime 2.702 (2.968)\tData 0.008 (0.044)\tLoss 5.5446 (6.1764)\tPrec@1 22.656 (15.722)\tPrec@5 35.156 (27.434)\n",
      "Epoch: [0][130/77344]\tTime 2.721 (2.948)\tData 0.009 (0.042)\tLoss 5.3452 (6.1025)\tPrec@1 26.562 (16.305)\tPrec@5 37.500 (28.256)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "train_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                      images_csv=\"train_images.csv\",\n",
    "                                      bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                      with_label=True,\n",
    "                                      resize=160)\n",
    "val_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                    images_csv=\"val_images.csv\",\n",
    "                                    bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                    with_label=True,\n",
    "                                    resize=160)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['val_batch_size'], shuffle=True, num_workers=6)\n",
    "\n",
    "# define model\n",
    "print(\"=> using pre-trained model '{}'\".format(config['arch']))\n",
    "model = models.__dict__[config['arch']](pretrained=config['pretrained'])\n",
    "\n",
    "# model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "# model.add_module('classifier', torch.nn.Linear(in_features=2048, out_features=5270))\n",
    "# model = torch.nn.DataParallel(model).cuda()\n",
    "# print(model)\n",
    "\n",
    "classifier_layer = [\n",
    "    torch.nn.Linear(in_features=12800, out_features=5270)\n",
    "]\n",
    "\n",
    "# classifier_layer = [\n",
    "#     torch.nn.Linear(in_features=2048, out_features=5270),\n",
    "# ]\n",
    "\n",
    "classifier = torch.nn.Sequential(*classifier_layer)\n",
    "\n",
    "model = assemble_model_with_classifier(model, -1, classifier)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "print(model)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# get trainer\n",
    "Trainer = get_trainer(train_dataloader, val_dataloader, model, criterion, config)\n",
    "\n",
    "# Run!\n",
    "Trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
