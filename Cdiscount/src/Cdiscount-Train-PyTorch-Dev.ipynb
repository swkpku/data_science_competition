{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model\n",
    "from trainer.trainer import get_trainer\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# redirect print to file\n",
    "# import sys\n",
    "# sys.stdout = open(\"PyTorch-resnet34-log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "config = {\n",
    "    'train_batch_size': 256, 'val_batch_size': 256,\n",
    "    'arch': 'resnet34',\n",
    "    'optimizer': 'Adam', 'learning_rate': 1e-4, 'decay_lr_freq': 1e4, 'weight_decay': 5e-4,\n",
    "    'resume': None,\n",
    "    'start_epoch': 0, 'epochs': 10,\n",
    "    'print_freq': 10, 'validate_freq': 3e4, 'save_freq': 1e3,\n",
    "    'best_val_prec1': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n",
      "=> using pre-trained model 'resnet34'\n",
      "start training\n",
      "Epoch: [0][0/38676]\tTime 25.487 (25.487)\tData 9.610 (9.610)\tLoss 8.8593 (8.8593)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][10/38676]\tTime 3.819 (5.682)\tData 0.000 (0.875)\tLoss 8.0490 (8.4861)\tPrec@1 3.125 (1.065)\tPrec@5 6.641 (2.060)\n",
      "Epoch: [0][20/38676]\tTime 3.797 (4.798)\tData 0.002 (0.459)\tLoss 7.4226 (8.1454)\tPrec@1 7.422 (3.497)\tPrec@5 13.672 (6.362)\n",
      "Epoch: [0][30/38676]\tTime 3.840 (4.486)\tData 0.002 (0.312)\tLoss 6.8526 (7.8094)\tPrec@1 8.594 (5.595)\tPrec@5 18.359 (10.068)\n",
      "Epoch: [0][40/38676]\tTime 3.803 (4.330)\tData 0.002 (0.237)\tLoss 6.4529 (7.5290)\tPrec@1 12.500 (7.269)\tPrec@5 21.875 (12.929)\n",
      "Epoch: [0][50/38676]\tTime 3.774 (4.230)\tData 0.002 (0.191)\tLoss 5.9713 (7.2841)\tPrec@1 17.578 (8.938)\tPrec@5 32.422 (15.862)\n",
      "Epoch: [0][60/38676]\tTime 3.808 (4.162)\tData 0.002 (0.160)\tLoss 6.3411 (7.0878)\tPrec@1 15.625 (10.220)\tPrec@5 26.172 (17.918)\n",
      "Epoch: [0][70/38676]\tTime 3.816 (4.115)\tData 0.002 (0.138)\tLoss 5.8409 (6.9100)\tPrec@1 17.578 (11.521)\tPrec@5 29.688 (19.916)\n",
      "Epoch: [0][80/38676]\tTime 3.819 (4.080)\tData 0.002 (0.121)\tLoss 5.9422 (6.7550)\tPrec@1 17.578 (12.683)\tPrec@5 28.906 (21.644)\n",
      "Epoch: [0][90/38676]\tTime 3.822 (4.053)\tData 0.003 (0.108)\tLoss 5.3764 (6.6318)\tPrec@1 24.609 (13.633)\tPrec@5 35.547 (23.051)\n",
      "Epoch: [0][100/38676]\tTime 3.796 (4.031)\tData 0.002 (0.097)\tLoss 5.3827 (6.5232)\tPrec@1 24.219 (14.500)\tPrec@5 35.547 (24.273)\n",
      "Epoch: [0][110/38676]\tTime 3.888 (4.013)\tData 0.003 (0.089)\tLoss 5.5115 (6.4317)\tPrec@1 23.047 (15.220)\tPrec@5 35.156 (25.239)\n",
      "Epoch: [0][120/38676]\tTime 3.840 (4.000)\tData 0.002 (0.082)\tLoss 5.2922 (6.3417)\tPrec@1 25.000 (15.990)\tPrec@5 39.844 (26.265)\n",
      "Epoch: [0][130/38676]\tTime 3.823 (3.986)\tData 0.002 (0.076)\tLoss 5.1075 (6.2612)\tPrec@1 23.047 (16.660)\tPrec@5 40.234 (27.189)\n",
      "Epoch: [0][140/38676]\tTime 3.823 (3.975)\tData 0.002 (0.070)\tLoss 5.2877 (6.1900)\tPrec@1 25.781 (17.262)\tPrec@5 35.156 (27.906)\n",
      "Epoch: [0][150/38676]\tTime 3.807 (3.965)\tData 0.010 (0.066)\tLoss 5.1277 (6.1132)\tPrec@1 27.344 (17.927)\tPrec@5 38.281 (28.800)\n",
      "Epoch: [0][160/38676]\tTime 3.851 (3.957)\tData 0.003 (0.062)\tLoss 5.0975 (6.0474)\tPrec@1 27.734 (18.544)\tPrec@5 41.797 (29.569)\n",
      "Epoch: [0][170/38676]\tTime 3.845 (3.950)\tData 0.002 (0.058)\tLoss 4.9000 (5.9930)\tPrec@1 30.078 (18.997)\tPrec@5 41.016 (30.190)\n",
      "Epoch: [0][180/38676]\tTime 3.814 (3.943)\tData 0.002 (0.055)\tLoss 5.0205 (5.9415)\tPrec@1 26.172 (19.460)\tPrec@5 41.797 (30.799)\n",
      "Epoch: [0][190/38676]\tTime 3.854 (3.937)\tData 0.002 (0.052)\tLoss 4.7635 (5.8959)\tPrec@1 30.078 (19.822)\tPrec@5 43.359 (31.320)\n",
      "Epoch: [0][200/38676]\tTime 3.772 (3.932)\tData 0.002 (0.050)\tLoss 4.8877 (5.8446)\tPrec@1 26.953 (20.262)\tPrec@5 39.062 (31.917)\n",
      "Epoch: [0][210/38676]\tTime 3.801 (3.926)\tData 0.002 (0.048)\tLoss 4.8383 (5.7961)\tPrec@1 28.125 (20.688)\tPrec@5 43.359 (32.463)\n",
      "Epoch: [0][220/38676]\tTime 3.818 (3.922)\tData 0.002 (0.046)\tLoss 4.7897 (5.7486)\tPrec@1 25.391 (21.058)\tPrec@5 45.312 (33.053)\n",
      "Epoch: [0][230/38676]\tTime 3.777 (3.917)\tData 0.002 (0.044)\tLoss 4.8987 (5.7062)\tPrec@1 27.734 (21.456)\tPrec@5 42.578 (33.518)\n",
      "Epoch: [0][240/38676]\tTime 3.845 (3.914)\tData 0.002 (0.042)\tLoss 4.7885 (5.6670)\tPrec@1 29.297 (21.809)\tPrec@5 43.359 (33.975)\n",
      "Epoch: [0][250/38676]\tTime 3.822 (3.911)\tData 0.001 (0.041)\tLoss 4.7072 (5.6256)\tPrec@1 30.469 (22.191)\tPrec@5 42.969 (34.443)\n",
      "Epoch: [0][260/38676]\tTime 3.867 (3.908)\tData 0.002 (0.039)\tLoss 4.6126 (5.5881)\tPrec@1 30.859 (22.480)\tPrec@5 47.656 (34.836)\n",
      "Epoch: [0][270/38676]\tTime 3.825 (3.905)\tData 0.002 (0.038)\tLoss 4.7455 (5.5578)\tPrec@1 30.078 (22.736)\tPrec@5 44.922 (35.189)\n",
      "Epoch: [0][280/38676]\tTime 3.801 (3.902)\tData 0.002 (0.036)\tLoss 4.6987 (5.5244)\tPrec@1 28.125 (23.019)\tPrec@5 44.922 (35.580)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "train_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                     images_csv=\"train_images.csv\",\n",
    "                                     with_label=True,\n",
    "                                     resize=256)\n",
    "val_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                     images_csv=\"val_images.csv\",\n",
    "                                     with_label=True,\n",
    "                                     resize=256)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['val_batch_size'], shuffle=True, num_workers=6)\n",
    "\n",
    "# define model\n",
    "print(\"=> using pre-trained model '{}'\".format(config['arch']))\n",
    "model = models.__dict__[config['arch']](pretrained=True)\n",
    "model = assemble_model(model, -1, 512, 5270)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# get trainer\n",
    "Trainer = get_trainer(train_dataloader, val_dataloader, model, criterion, config)\n",
    "\n",
    "# Run!\n",
    "Trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
