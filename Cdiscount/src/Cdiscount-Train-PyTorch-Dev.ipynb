{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model\n",
    "from trainer.trainer import get_trainer\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# redirect print to file\n",
    "# import sys\n",
    "# sys.stdout = open(\"PyTorch-resnet34-log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "config = {\n",
    "    'train_batch_size': 48, 'val_batch_size': 48,\n",
    "    'arch': 'resnet152',\n",
    "    'optimizer': 'Adam', 'learning_rate': 5e-6, 'decay_lr_freq': 3e5, 'weight_decay': 5e-4,\n",
    "    'resume': None,\n",
    "    'start_epoch': 0, 'epochs': 10,\n",
    "    'print_freq': 10, 'validate_freq': 3e4, 'save_freq': 1e3,\n",
    "    'best_val_prec1': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n",
      "=> using pre-trained model 'resnet152'\n",
      "start training\n",
      "Epoch: [0][0/206270]\tTime 23.269 (23.269)\tData 3.325 (3.325)\tLoss 8.6347 (8.6347)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][10/206270]\tTime 2.559 (4.451)\tData 0.007 (0.310)\tLoss 8.6234 (8.6162)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][20/206270]\tTime 2.557 (3.543)\tData 0.009 (0.167)\tLoss 8.6363 (8.6019)\tPrec@1 0.000 (0.000)\tPrec@5 2.083 (0.397)\n",
      "Epoch: [0][30/206270]\tTime 2.564 (3.226)\tData 0.009 (0.116)\tLoss 8.5990 (8.5756)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.336)\n",
      "Epoch: [0][40/206270]\tTime 2.549 (3.063)\tData 0.008 (0.090)\tLoss 8.4095 (8.5665)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.254)\n",
      "Epoch: [0][50/206270]\tTime 2.558 (2.963)\tData 0.018 (0.074)\tLoss 8.5124 (8.5533)\tPrec@1 0.000 (0.000)\tPrec@5 4.167 (0.408)\n",
      "Epoch: [0][60/206270]\tTime 2.562 (2.898)\tData 0.008 (0.064)\tLoss 8.4454 (8.5297)\tPrec@1 0.000 (0.102)\tPrec@5 0.000 (0.444)\n",
      "Epoch: [0][70/206270]\tTime 2.546 (2.851)\tData 0.008 (0.056)\tLoss 8.4331 (8.5154)\tPrec@1 2.083 (0.117)\tPrec@5 2.083 (0.440)\n",
      "Epoch: [0][80/206270]\tTime 2.571 (2.815)\tData 0.009 (0.050)\tLoss 8.2963 (8.4938)\tPrec@1 2.083 (0.154)\tPrec@5 2.083 (0.514)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "train_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                      images_csv=\"train_images.csv\",\n",
    "                                      bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                      with_label=True,\n",
    "                                      resize=224)\n",
    "val_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                    images_csv=\"val_images.csv\",\n",
    "                                    bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                    with_label=True,\n",
    "                                    resize=224)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['val_batch_size'], shuffle=True, num_workers=6)\n",
    "\n",
    "# define model\n",
    "print(\"=> using pre-trained model '{}'\".format(config['arch']))\n",
    "model = models.__dict__[config['arch']](pretrained=True)\n",
    "model = assemble_model(model, -1, 2048, 5270)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# get trainer\n",
    "Trainer = get_trainer(train_dataloader, val_dataloader, model, criterion, config)\n",
    "\n",
    "# Run!\n",
    "Trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
