{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import bson\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import concurrent.futures\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_images = 1000000\n",
    "im_size = 16\n",
    "num_cpus = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2e67b7dca44a658f05955e4e268424"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imread(buf):\n",
    "    return cv2.imdecode(np.frombuffer(buf, np.uint8), cv2.IMREAD_ANYCOLOR)\n",
    "\n",
    "def img2feat(im):\n",
    "    x = cv2.resize(im, (im_size, im_size), interpolation=cv2.INTER_AREA)\n",
    "    return np.float32(x) / 255\n",
    "\n",
    "images = np.empty((num_images, im_size, im_size, 3), dtype=np.float32)\n",
    "labels = []\n",
    "\n",
    "def load_image(pic, target, bar):\n",
    "    picture = imread(pic)\n",
    "    x = img2feat(picture)\n",
    "    bar.update()\n",
    "    \n",
    "    return x, target\n",
    "\n",
    "bar = tqdm_notebook(total=num_images)\n",
    "with open('/mnt/data/cdiscount/train.bson', 'rb') as f, \\\n",
    "        concurrent.futures.ThreadPoolExecutor(num_cpus) as executor:\n",
    "\n",
    "    data = bson.decode_file_iter(f)\n",
    "    delayed_load = []\n",
    "\n",
    "    i = 0\n",
    "    try:\n",
    "        for c, d in enumerate(data):\n",
    "            target = d['category_id']\n",
    "            for e, pic in enumerate(d['imgs']):\n",
    "                delayed_load.append(executor.submit(load_image, pic['picture'], target, bar))\n",
    "                \n",
    "                i = i + 1\n",
    "\n",
    "                if i >= num_images:\n",
    "                    raise IndexError()\n",
    "\n",
    "    except IndexError:\n",
    "        pass;\n",
    "    \n",
    "    for i, future in enumerate(concurrent.futures.as_completed(delayed_load)):\n",
    "        x, target = future.result()\n",
    "        \n",
    "        images[i] = x\n",
    "        labels.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 16, 16, 3), 1000000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885605\n"
     ]
    }
   ],
   "source": [
    "labels = pd.Series(labels)\n",
    "\n",
    "num_classes = 1000 \n",
    "valid_targets = set(labels.value_counts().index[:num_classes-1].tolist())\n",
    "valid_labels = labels.isin(valid_targets)\n",
    "\n",
    "labels[~valid_labels] = -1\n",
    "\n",
    "max_acc = valid_labels.mean()\n",
    "print(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels, rev_labels = pd.factorize(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "labels.shape\n",
    "print(labels[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image shape:  (900000, 16, 16, 3)\n",
      "train label shape:  (900000,)\n",
      "val image shape:  (100000, 16, 16, 3)\n",
      "val label shape:  (100000,)\n"
     ]
    }
   ],
   "source": [
    "num_train = 900000\n",
    "num_val   = 100000\n",
    "\n",
    "indicies = np.arange(num_images)\n",
    "np.random.shuffle(indicies)\n",
    "train_mask = indicies[range(num_train)]\n",
    "val_mask = indicies[range(num_train, num_train + num_val)]\n",
    "\n",
    "train_image = images[train_mask]\n",
    "train_label = labels[train_mask]\n",
    "val_image = images[val_mask]\n",
    "val_label = labels[val_mask]\n",
    "\n",
    "print('train image shape: ', train_image.shape)\n",
    "print('train label shape: ', train_label.shape)\n",
    "print('val image shape: ', val_image.shape)\n",
    "print('val label shape: ', val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with batch_size: 128, learning_rate: 0.000050\n",
      "epoch 0:\n",
      "1000000/|/100%|| 1000000/1000000 [03:40<00:00, 6066.73it/s]iter: 0, loss: 7.673796, acc: 0.000000\n",
      "iter: 1000, loss: 4.364858, acc: 0.304688\n",
      "iter: 2000, loss: 3.918566, acc: 0.320312\n",
      "iter: 3000, loss: 4.429805, acc: 0.296875\n",
      "iter: 4000, loss: 3.528655, acc: 0.375000\n",
      "iter: 5000, loss: 3.568255, acc: 0.335938\n",
      "iter: 6000, loss: 3.347727, acc: 0.390625\n",
      "iter: 7000, loss: 3.575685, acc: 0.343750\n",
      "val set acc: 0.387100\n",
      "val set acc: 0.387400\n",
      "val set acc: 0.385600\n",
      "val set acc: 0.385600\n",
      "val set acc: 0.381600\n",
      "val set acc: 0.385700\n",
      "val set acc: 0.379400\n",
      "val set acc: 0.384400\n",
      "val set acc: 0.389300\n",
      "val set acc: 0.390000\n",
      "epoch 1:\n",
      "iter: 0, loss: 3.328668, acc: 0.382812\n",
      "iter: 1000, loss: 3.414106, acc: 0.398438\n",
      "iter: 2000, loss: 3.286784, acc: 0.429688\n",
      "iter: 3000, loss: 3.814872, acc: 0.328125\n",
      "iter: 4000, loss: 2.782917, acc: 0.437500\n",
      "iter: 5000, loss: 3.126467, acc: 0.398438\n",
      "iter: 6000, loss: 2.914015, acc: 0.445312\n",
      "iter: 7000, loss: 3.140428, acc: 0.398438\n",
      "val set acc: 0.422600\n",
      "val set acc: 0.426500\n",
      "val set acc: 0.425100\n",
      "val set acc: 0.431400\n",
      "val set acc: 0.422200\n",
      "val set acc: 0.417800\n",
      "val set acc: 0.419000\n",
      "val set acc: 0.422500\n",
      "val set acc: 0.427100\n",
      "val set acc: 0.431800\n",
      "epoch 2:\n",
      "iter: 0, loss: 2.992672, acc: 0.429688\n",
      "iter: 1000, loss: 3.029741, acc: 0.437500\n",
      "iter: 2000, loss: 2.994484, acc: 0.500000\n",
      "iter: 3000, loss: 3.538596, acc: 0.351562\n",
      "iter: 4000, loss: 2.410994, acc: 0.515625\n",
      "iter: 5000, loss: 2.872492, acc: 0.437500\n",
      "iter: 6000, loss: 2.635167, acc: 0.500000\n",
      "iter: 7000, loss: 2.886712, acc: 0.460938\n",
      "val set acc: 0.442800\n",
      "val set acc: 0.447700\n",
      "val set acc: 0.447100\n",
      "val set acc: 0.449900\n",
      "val set acc: 0.444100\n",
      "val set acc: 0.438600\n",
      "val set acc: 0.439400\n",
      "val set acc: 0.444100\n",
      "val set acc: 0.445300\n",
      "val set acc: 0.447900\n",
      "epoch 3:\n",
      "iter: 0, loss: 2.824374, acc: 0.437500\n",
      "iter: 1000, loss: 2.819690, acc: 0.476562\n",
      "iter: 2000, loss: 2.776239, acc: 0.500000\n",
      "iter: 3000, loss: 3.366130, acc: 0.359375\n",
      "iter: 4000, loss: 2.173598, acc: 0.570312\n",
      "iter: 5000, loss: 2.670679, acc: 0.468750\n",
      "iter: 6000, loss: 2.466193, acc: 0.539062\n",
      "iter: 7000, loss: 2.722915, acc: 0.507812\n",
      "val set acc: 0.456300\n",
      "val set acc: 0.455600\n",
      "val set acc: 0.458300\n",
      "val set acc: 0.458100\n",
      "val set acc: 0.454200\n",
      "val set acc: 0.449400\n",
      "val set acc: 0.448000\n",
      "val set acc: 0.456600\n",
      "val set acc: 0.456500\n",
      "val set acc: 0.460000\n",
      "epoch 4:\n",
      "iter: 0, loss: 2.662332, acc: 0.453125\n",
      "iter: 1000, loss: 2.642200, acc: 0.468750\n",
      "iter: 2000, loss: 2.593651, acc: 0.515625\n",
      "iter: 3000, loss: 3.180979, acc: 0.398438\n",
      "iter: 4000, loss: 2.035718, acc: 0.601562\n",
      "iter: 5000, loss: 2.503407, acc: 0.515625\n",
      "iter: 6000, loss: 2.316811, acc: 0.562500\n",
      "iter: 7000, loss: 2.561674, acc: 0.507812\n",
      "val set acc: 0.464600\n",
      "val set acc: 0.465900\n",
      "val set acc: 0.464200\n",
      "val set acc: 0.466000\n",
      "val set acc: 0.461300\n",
      "val set acc: 0.456200\n",
      "val set acc: 0.455800\n",
      "val set acc: 0.461800\n",
      "val set acc: 0.463300\n",
      "val set acc: 0.469200\n",
      "epoch 5:\n",
      "iter: 0, loss: 2.533297, acc: 0.460938\n",
      "iter: 1000, loss: 2.461583, acc: 0.476562\n",
      "iter: 2000, loss: 2.415128, acc: 0.515625\n",
      "iter: 3000, loss: 3.016267, acc: 0.421875\n",
      "iter: 4000, loss: 1.909997, acc: 0.625000\n",
      "iter: 5000, loss: 2.350411, acc: 0.531250\n",
      "iter: 6000, loss: 2.216986, acc: 0.562500\n",
      "iter: 7000, loss: 2.457928, acc: 0.531250\n",
      "val set acc: 0.469100\n",
      "val set acc: 0.469900\n",
      "val set acc: 0.469400\n",
      "val set acc: 0.469000\n",
      "val set acc: 0.467000\n",
      "val set acc: 0.460000\n",
      "val set acc: 0.463400\n",
      "val set acc: 0.469200\n",
      "val set acc: 0.469800\n",
      "val set acc: 0.470500\n",
      "epoch 6:\n",
      "iter: 0, loss: 2.399950, acc: 0.468750\n",
      "iter: 1000, loss: 2.309428, acc: 0.484375\n",
      "iter: 2000, loss: 2.299057, acc: 0.523438\n",
      "iter: 3000, loss: 2.881086, acc: 0.414062\n",
      "iter: 4000, loss: 1.825359, acc: 0.640625\n",
      "iter: 5000, loss: 2.229569, acc: 0.523438\n",
      "iter: 6000, loss: 2.130054, acc: 0.593750\n",
      "iter: 7000, loss: 2.326696, acc: 0.554688\n",
      "val set acc: 0.470100\n",
      "val set acc: 0.475200\n",
      "val set acc: 0.472700\n",
      "val set acc: 0.471300\n",
      "val set acc: 0.470400\n",
      "val set acc: 0.464000\n",
      "val set acc: 0.465600\n",
      "val set acc: 0.471900\n",
      "val set acc: 0.472400\n",
      "val set acc: 0.473300\n",
      "epoch 7:\n",
      "iter: 0, loss: 2.307399, acc: 0.476562\n",
      "iter: 1000, loss: 2.215456, acc: 0.515625\n",
      "iter: 2000, loss: 2.163191, acc: 0.554688\n",
      "iter: 3000, loss: 2.759212, acc: 0.437500\n",
      "iter: 4000, loss: 1.731189, acc: 0.625000\n",
      "iter: 5000, loss: 2.116410, acc: 0.531250\n",
      "iter: 6000, loss: 2.048924, acc: 0.585938\n",
      "iter: 7000, loss: 2.228890, acc: 0.570312\n",
      "val set acc: 0.471400\n",
      "val set acc: 0.476500\n",
      "val set acc: 0.472400\n",
      "val set acc: 0.471400\n",
      "val set acc: 0.470500\n",
      "val set acc: 0.462400\n",
      "val set acc: 0.470600\n",
      "val set acc: 0.470500\n",
      "val set acc: 0.474600\n",
      "val set acc: 0.472500\n",
      "epoch 8:\n",
      "iter: 0, loss: 2.241107, acc: 0.484375\n",
      "iter: 1000, loss: 2.111758, acc: 0.539062\n",
      "iter: 2000, loss: 2.046809, acc: 0.554688\n",
      "iter: 3000, loss: 2.634020, acc: 0.453125\n",
      "iter: 4000, loss: 1.632876, acc: 0.640625\n",
      "iter: 5000, loss: 2.041078, acc: 0.546875\n",
      "iter: 6000, loss: 1.948443, acc: 0.601562\n",
      "iter: 7000, loss: 2.165619, acc: 0.585938\n",
      "val set acc: 0.472600\n",
      "val set acc: 0.476000\n",
      "val set acc: 0.473400\n",
      "val set acc: 0.472700\n",
      "val set acc: 0.472600\n",
      "val set acc: 0.465500\n",
      "val set acc: 0.473500\n",
      "val set acc: 0.473700\n",
      "val set acc: 0.473600\n",
      "val set acc: 0.477200\n",
      "epoch 9:\n",
      "iter: 0, loss: 2.147804, acc: 0.492188\n",
      "iter: 1000, loss: 2.022940, acc: 0.570312\n",
      "iter: 2000, loss: 1.926017, acc: 0.578125\n",
      "iter: 3000, loss: 2.526989, acc: 0.468750\n",
      "iter: 4000, loss: 1.550470, acc: 0.656250\n",
      "iter: 5000, loss: 1.964573, acc: 0.554688\n",
      "iter: 6000, loss: 1.890736, acc: 0.609375\n",
      "iter: 7000, loss: 2.056689, acc: 0.593750\n",
      "val set acc: 0.473900\n",
      "val set acc: 0.475700\n",
      "val set acc: 0.475100\n",
      "val set acc: 0.469700\n",
      "val set acc: 0.473900\n",
      "val set acc: 0.463800\n",
      "val set acc: 0.473600\n",
      "val set acc: 0.473000\n",
      "val set acc: 0.475100\n",
      "val set acc: 0.474700\n",
      "epoch 10:\n",
      "iter: 0, loss: 2.111777, acc: 0.531250\n",
      "iter: 1000, loss: 1.948166, acc: 0.585938\n",
      "iter: 2000, loss: 1.830508, acc: 0.609375\n",
      "iter: 3000, loss: 2.427496, acc: 0.460938\n",
      "iter: 4000, loss: 1.490537, acc: 0.640625\n",
      "iter: 5000, loss: 1.877515, acc: 0.570312\n",
      "iter: 6000, loss: 1.816046, acc: 0.617188\n",
      "iter: 7000, loss: 1.988539, acc: 0.609375\n",
      "val set acc: 0.473500\n",
      "val set acc: 0.475100\n",
      "val set acc: 0.476500\n",
      "val set acc: 0.471200\n",
      "val set acc: 0.470100\n",
      "val set acc: 0.463900\n",
      "val set acc: 0.471900\n",
      "val set acc: 0.470700\n",
      "val set acc: 0.473900\n",
      "val set acc: 0.473400\n",
      "epoch 11:\n",
      "iter: 0, loss: 2.097524, acc: 0.531250\n",
      "iter: 1000, loss: 1.857286, acc: 0.585938\n",
      "iter: 2000, loss: 1.736367, acc: 0.609375\n",
      "iter: 3000, loss: 2.345762, acc: 0.484375\n",
      "iter: 4000, loss: 1.456942, acc: 0.609375\n",
      "iter: 5000, loss: 1.791625, acc: 0.562500\n",
      "iter: 6000, loss: 1.768287, acc: 0.656250\n",
      "iter: 7000, loss: 1.956831, acc: 0.585938\n",
      "val set acc: 0.472900\n",
      "val set acc: 0.474100\n",
      "val set acc: 0.474500\n",
      "val set acc: 0.469400\n",
      "val set acc: 0.473200\n",
      "val set acc: 0.462600\n",
      "val set acc: 0.474100\n",
      "val set acc: 0.471700\n",
      "val set acc: 0.474500\n",
      "val set acc: 0.472200\n",
      "epoch 12:\n",
      "iter: 0, loss: 2.070814, acc: 0.523438\n",
      "iter: 1000, loss: 1.786142, acc: 0.640625\n",
      "iter: 2000, loss: 1.658721, acc: 0.625000\n",
      "iter: 3000, loss: 2.274032, acc: 0.500000\n",
      "iter: 4000, loss: 1.433208, acc: 0.625000\n",
      "iter: 5000, loss: 1.696995, acc: 0.585938\n",
      "iter: 6000, loss: 1.715996, acc: 0.656250\n",
      "iter: 7000, loss: 1.886377, acc: 0.617188\n",
      "val set acc: 0.473300\n",
      "val set acc: 0.474700\n",
      "val set acc: 0.475000\n",
      "val set acc: 0.472100\n",
      "val set acc: 0.472200\n",
      "val set acc: 0.462200\n",
      "val set acc: 0.475600\n",
      "val set acc: 0.469900\n",
      "val set acc: 0.474600\n",
      "val set acc: 0.470100\n",
      "epoch 13:\n",
      "iter: 0, loss: 2.037390, acc: 0.539062\n",
      "iter: 1000, loss: 1.724450, acc: 0.640625\n",
      "iter: 2000, loss: 1.589410, acc: 0.632812\n",
      "iter: 3000, loss: 2.214996, acc: 0.507812\n",
      "iter: 4000, loss: 1.371730, acc: 0.656250\n",
      "iter: 5000, loss: 1.628295, acc: 0.601562\n",
      "iter: 6000, loss: 1.680064, acc: 0.656250\n",
      "iter: 7000, loss: 1.834048, acc: 0.632812\n",
      "val set acc: 0.467700\n",
      "val set acc: 0.473400\n",
      "val set acc: 0.474900\n",
      "val set acc: 0.468200\n",
      "val set acc: 0.468500\n",
      "val set acc: 0.462200\n",
      "val set acc: 0.472800\n",
      "val set acc: 0.469000\n",
      "val set acc: 0.472300\n",
      "val set acc: 0.470300\n",
      "epoch 14:\n",
      "iter: 0, loss: 1.975762, acc: 0.562500\n",
      "iter: 1000, loss: 1.690128, acc: 0.640625\n",
      "iter: 2000, loss: 1.536579, acc: 0.656250\n",
      "iter: 3000, loss: 2.135201, acc: 0.515625\n",
      "iter: 4000, loss: 1.300115, acc: 0.664062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 5000, loss: 1.583876, acc: 0.601562\n",
      "iter: 6000, loss: 1.629793, acc: 0.648438\n",
      "iter: 7000, loss: 1.781545, acc: 0.632812\n",
      "val set acc: 0.468700\n",
      "val set acc: 0.472400\n",
      "val set acc: 0.473000\n",
      "val set acc: 0.467400\n",
      "val set acc: 0.468600\n",
      "val set acc: 0.461600\n",
      "val set acc: 0.469300\n",
      "val set acc: 0.467300\n",
      "val set acc: 0.472600\n",
      "val set acc: 0.469100\n",
      "epoch 15:\n",
      "iter: 0, loss: 1.934668, acc: 0.578125\n",
      "iter: 1000, loss: 1.649989, acc: 0.640625\n",
      "iter: 2000, loss: 1.473223, acc: 0.664062\n",
      "iter: 3000, loss: 2.065703, acc: 0.507812\n",
      "iter: 4000, loss: 1.272004, acc: 0.671875\n",
      "iter: 5000, loss: 1.538751, acc: 0.617188\n",
      "iter: 6000, loss: 1.576609, acc: 0.632812\n",
      "iter: 7000, loss: 1.732420, acc: 0.664062\n",
      "val set acc: 0.466000\n",
      "val set acc: 0.471000\n",
      "val set acc: 0.473200\n",
      "val set acc: 0.464600\n",
      "val set acc: 0.466900\n",
      "val set acc: 0.460200\n",
      "val set acc: 0.468100\n",
      "val set acc: 0.467200\n",
      "val set acc: 0.471300\n",
      "val set acc: 0.469900\n",
      "epoch 16:\n",
      "iter: 0, loss: 1.908231, acc: 0.562500\n",
      "iter: 1000, loss: 1.607094, acc: 0.656250\n",
      "iter: 2000, loss: 1.437720, acc: 0.671875\n",
      "iter: 3000, loss: 2.016156, acc: 0.523438\n",
      "iter: 4000, loss: 1.229888, acc: 0.664062\n",
      "iter: 5000, loss: 1.490945, acc: 0.640625\n",
      "iter: 6000, loss: 1.529171, acc: 0.640625\n",
      "iter: 7000, loss: 1.679291, acc: 0.664062\n",
      "val set acc: 0.469200\n",
      "val set acc: 0.472300\n",
      "val set acc: 0.471600\n",
      "val set acc: 0.467200\n",
      "val set acc: 0.465500\n",
      "val set acc: 0.459500\n",
      "val set acc: 0.469100\n",
      "val set acc: 0.467800\n",
      "val set acc: 0.470100\n",
      "val set acc: 0.467700\n",
      "epoch 17:\n",
      "iter: 0, loss: 1.842981, acc: 0.570312\n",
      "iter: 1000, loss: 1.551911, acc: 0.664062\n",
      "iter: 2000, loss: 1.381951, acc: 0.679688\n",
      "iter: 3000, loss: 1.955790, acc: 0.507812\n",
      "iter: 4000, loss: 1.218575, acc: 0.664062\n",
      "iter: 5000, loss: 1.448347, acc: 0.671875\n",
      "iter: 6000, loss: 1.501534, acc: 0.640625\n",
      "iter: 7000, loss: 1.643625, acc: 0.671875\n",
      "val set acc: 0.469900\n",
      "val set acc: 0.472000\n",
      "val set acc: 0.472100\n",
      "val set acc: 0.464500\n",
      "val set acc: 0.465300\n",
      "val set acc: 0.460000\n",
      "val set acc: 0.468600\n",
      "val set acc: 0.468700\n",
      "val set acc: 0.470500\n",
      "val set acc: 0.468400\n",
      "epoch 18:\n",
      "iter: 0, loss: 1.824720, acc: 0.570312\n",
      "iter: 1000, loss: 1.503253, acc: 0.664062\n",
      "iter: 2000, loss: 1.341671, acc: 0.648438\n",
      "iter: 3000, loss: 1.915658, acc: 0.531250\n",
      "iter: 4000, loss: 1.182569, acc: 0.648438\n",
      "iter: 5000, loss: 1.379831, acc: 0.703125\n",
      "iter: 6000, loss: 1.469899, acc: 0.656250\n",
      "iter: 7000, loss: 1.619671, acc: 0.671875\n",
      "val set acc: 0.468900\n",
      "val set acc: 0.471600\n",
      "val set acc: 0.470700\n",
      "val set acc: 0.463700\n",
      "val set acc: 0.463400\n",
      "val set acc: 0.458500\n",
      "val set acc: 0.468600\n",
      "val set acc: 0.465800\n",
      "val set acc: 0.471500\n",
      "val set acc: 0.464800\n",
      "epoch 19:\n",
      "iter: 0, loss: 1.794395, acc: 0.585938\n",
      "iter: 1000, loss: 1.466227, acc: 0.671875\n",
      "iter: 2000, loss: 1.278834, acc: 0.687500\n",
      "iter: 3000, loss: 1.860372, acc: 0.546875\n",
      "iter: 4000, loss: 1.159988, acc: 0.648438\n",
      "iter: 5000, loss: 1.357243, acc: 0.687500\n",
      "iter: 6000, loss: 1.431679, acc: 0.679688\n",
      "iter: 7000, loss: 1.602376, acc: 0.679688\n",
      "val set acc: 0.467000\n",
      "val set acc: 0.469600\n",
      "val set acc: 0.468900\n",
      "val set acc: 0.461800\n",
      "val set acc: 0.461800\n",
      "val set acc: 0.455800\n",
      "val set acc: 0.467800\n",
      "val set acc: 0.463200\n",
      "val set acc: 0.469300\n",
      "val set acc: 0.464400\n",
      "epoch 20:\n",
      "iter: 0, loss: 1.765177, acc: 0.570312\n",
      "iter: 1000, loss: 1.445827, acc: 0.671875\n",
      "iter: 2000, loss: 1.254896, acc: 0.695312\n",
      "iter: 3000, loss: 1.790144, acc: 0.570312\n",
      "iter: 4000, loss: 1.114391, acc: 0.671875\n",
      "iter: 5000, loss: 1.305187, acc: 0.703125\n",
      "iter: 6000, loss: 1.402317, acc: 0.695312\n",
      "iter: 7000, loss: 1.551709, acc: 0.671875\n",
      "val set acc: 0.468300\n",
      "val set acc: 0.467200\n",
      "val set acc: 0.468800\n",
      "val set acc: 0.461900\n",
      "val set acc: 0.459400\n",
      "val set acc: 0.455800\n",
      "val set acc: 0.468100\n",
      "val set acc: 0.464500\n",
      "val set acc: 0.470700\n",
      "val set acc: 0.463500\n",
      "epoch 21:\n",
      "iter: 0, loss: 1.748191, acc: 0.578125\n",
      "iter: 1000, loss: 1.421934, acc: 0.671875\n",
      "iter: 2000, loss: 1.235109, acc: 0.695312\n",
      "iter: 3000, loss: 1.748438, acc: 0.570312\n",
      "iter: 4000, loss: 1.090290, acc: 0.679688\n",
      "iter: 5000, loss: 1.286072, acc: 0.726562\n",
      "iter: 6000, loss: 1.369229, acc: 0.687500\n",
      "iter: 7000, loss: 1.535223, acc: 0.664062\n",
      "val set acc: 0.467600\n",
      "val set acc: 0.465400\n",
      "val set acc: 0.469800\n",
      "val set acc: 0.460500\n",
      "val set acc: 0.458500\n",
      "val set acc: 0.454500\n",
      "val set acc: 0.468500\n",
      "val set acc: 0.461400\n",
      "val set acc: 0.469300\n",
      "val set acc: 0.464500\n",
      "epoch 22:\n",
      "iter: 0, loss: 1.731323, acc: 0.578125\n",
      "iter: 1000, loss: 1.380760, acc: 0.671875\n",
      "iter: 2000, loss: 1.181206, acc: 0.718750\n",
      "iter: 3000, loss: 1.701756, acc: 0.554688\n",
      "iter: 4000, loss: 1.056323, acc: 0.695312\n",
      "iter: 5000, loss: 1.254791, acc: 0.710938\n",
      "iter: 6000, loss: 1.334033, acc: 0.695312\n",
      "iter: 7000, loss: 1.491244, acc: 0.703125\n",
      "val set acc: 0.464100\n",
      "val set acc: 0.464700\n",
      "val set acc: 0.469500\n",
      "val set acc: 0.460100\n",
      "val set acc: 0.457100\n",
      "val set acc: 0.453200\n",
      "val set acc: 0.464400\n",
      "val set acc: 0.462800\n",
      "val set acc: 0.469400\n",
      "val set acc: 0.462500\n",
      "epoch 23:\n",
      "iter: 0, loss: 1.722914, acc: 0.578125\n",
      "iter: 1000, loss: 1.374354, acc: 0.687500\n",
      "iter: 2000, loss: 1.134879, acc: 0.734375\n",
      "iter: 3000, loss: 1.661266, acc: 0.585938\n",
      "iter: 4000, loss: 1.035136, acc: 0.710938\n",
      "iter: 5000, loss: 1.227044, acc: 0.718750\n",
      "iter: 6000, loss: 1.311449, acc: 0.687500\n",
      "iter: 7000, loss: 1.488060, acc: 0.703125\n",
      "val set acc: 0.463100\n",
      "val set acc: 0.464400\n",
      "val set acc: 0.468000\n",
      "val set acc: 0.460100\n",
      "val set acc: 0.458700\n",
      "val set acc: 0.452300\n",
      "val set acc: 0.463700\n",
      "val set acc: 0.462200\n",
      "val set acc: 0.470400\n",
      "val set acc: 0.460200\n",
      "epoch 24:\n",
      "iter: 0, loss: 1.696966, acc: 0.578125\n",
      "iter: 1000, loss: 1.351577, acc: 0.695312\n",
      "iter: 2000, loss: 1.122935, acc: 0.757812\n",
      "iter: 3000, loss: 1.620198, acc: 0.609375\n",
      "iter: 4000, loss: 1.021374, acc: 0.726562\n",
      "iter: 5000, loss: 1.202412, acc: 0.742188\n",
      "iter: 6000, loss: 1.290694, acc: 0.703125\n",
      "iter: 7000, loss: 1.481573, acc: 0.695312\n",
      "val set acc: 0.464300\n",
      "val set acc: 0.463300\n",
      "val set acc: 0.468600\n",
      "val set acc: 0.459100\n",
      "val set acc: 0.456500\n",
      "val set acc: 0.450100\n",
      "val set acc: 0.462500\n",
      "val set acc: 0.458800\n",
      "val set acc: 0.468300\n",
      "val set acc: 0.459900\n",
      "epoch 25:\n",
      "iter: 0, loss: 1.679123, acc: 0.601562\n",
      "iter: 1000, loss: 1.338383, acc: 0.695312\n",
      "iter: 2000, loss: 1.091054, acc: 0.773438\n",
      "iter: 3000, loss: 1.581632, acc: 0.609375\n",
      "iter: 4000, loss: 1.020828, acc: 0.734375\n",
      "iter: 5000, loss: 1.189721, acc: 0.726562\n",
      "iter: 6000, loss: 1.247766, acc: 0.695312\n",
      "iter: 7000, loss: 1.488171, acc: 0.703125\n",
      "val set acc: 0.459900\n",
      "val set acc: 0.461200\n",
      "val set acc: 0.465500\n",
      "val set acc: 0.458000\n",
      "val set acc: 0.456400\n",
      "val set acc: 0.447400\n",
      "val set acc: 0.461300\n",
      "val set acc: 0.461200\n",
      "val set acc: 0.468300\n",
      "val set acc: 0.457000\n",
      "epoch 26:\n",
      "iter: 0, loss: 1.678599, acc: 0.585938\n",
      "iter: 1000, loss: 1.321939, acc: 0.703125\n",
      "iter: 2000, loss: 1.067366, acc: 0.750000\n",
      "iter: 3000, loss: 1.568371, acc: 0.625000\n",
      "iter: 4000, loss: 1.007866, acc: 0.726562\n",
      "iter: 5000, loss: 1.157574, acc: 0.726562\n",
      "iter: 6000, loss: 1.228149, acc: 0.679688\n",
      "iter: 7000, loss: 1.460728, acc: 0.687500\n",
      "val set acc: 0.461400\n",
      "val set acc: 0.461900\n",
      "val set acc: 0.467700\n",
      "val set acc: 0.457200\n",
      "val set acc: 0.456000\n",
      "val set acc: 0.449100\n",
      "val set acc: 0.461800\n",
      "val set acc: 0.459500\n",
      "val set acc: 0.467900\n",
      "val set acc: 0.456600\n",
      "epoch 27:\n",
      "iter: 0, loss: 1.633165, acc: 0.593750\n",
      "iter: 1000, loss: 1.308425, acc: 0.671875\n",
      "iter: 2000, loss: 1.041423, acc: 0.757812\n",
      "iter: 3000, loss: 1.514626, acc: 0.640625\n",
      "iter: 4000, loss: 0.993439, acc: 0.734375\n",
      "iter: 5000, loss: 1.148005, acc: 0.742188\n",
      "iter: 6000, loss: 1.214876, acc: 0.710938\n",
      "iter: 7000, loss: 1.448990, acc: 0.695312\n",
      "val set acc: 0.460300\n",
      "val set acc: 0.459500\n",
      "val set acc: 0.465700\n",
      "val set acc: 0.456500\n",
      "val set acc: 0.453900\n",
      "val set acc: 0.447100\n",
      "val set acc: 0.460100\n",
      "val set acc: 0.458600\n",
      "val set acc: 0.468100\n",
      "val set acc: 0.457100\n",
      "epoch 28:\n",
      "iter: 0, loss: 1.601533, acc: 0.609375\n",
      "iter: 1000, loss: 1.263851, acc: 0.710938\n",
      "iter: 2000, loss: 1.011797, acc: 0.765625\n",
      "iter: 3000, loss: 1.487918, acc: 0.648438\n",
      "iter: 4000, loss: 0.977022, acc: 0.718750\n",
      "iter: 5000, loss: 1.086244, acc: 0.757812\n",
      "iter: 6000, loss: 1.198445, acc: 0.710938\n",
      "iter: 7000, loss: 1.434360, acc: 0.710938\n",
      "val set acc: 0.459400\n",
      "val set acc: 0.458100\n",
      "val set acc: 0.465000\n",
      "val set acc: 0.454200\n",
      "val set acc: 0.450900\n",
      "val set acc: 0.445400\n",
      "val set acc: 0.460500\n",
      "val set acc: 0.456300\n",
      "val set acc: 0.465900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set acc: 0.453000\n",
      "epoch 29:\n",
      "iter: 0, loss: 1.558527, acc: 0.609375\n",
      "iter: 1000, loss: 1.253363, acc: 0.687500\n",
      "iter: 2000, loss: 1.001430, acc: 0.750000\n",
      "iter: 3000, loss: 1.462026, acc: 0.656250\n",
      "iter: 4000, loss: 0.953269, acc: 0.734375\n",
      "iter: 5000, loss: 1.057895, acc: 0.757812\n",
      "iter: 6000, loss: 1.186240, acc: 0.718750\n",
      "iter: 7000, loss: 1.433279, acc: 0.695312\n",
      "val set acc: 0.460000\n",
      "val set acc: 0.457400\n",
      "val set acc: 0.462400\n",
      "val set acc: 0.453900\n",
      "val set acc: 0.451500\n",
      "val set acc: 0.444900\n",
      "val set acc: 0.457800\n",
      "val set acc: 0.455000\n",
      "val set acc: 0.462500\n",
      "val set acc: 0.454500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiso/tensorflow/lib/python3.5/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4536364it [3:41:32, 330.37it/s]done!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "val_batch_size = 10000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "num_test = 60000#test_images.shape[0]\n",
    "\n",
    "def model(x):\n",
    "    x = tf.reshape(x, [-1, 16, 16, 3])\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[2, 2], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)    \n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[2, 2], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True) \n",
    "\n",
    "    x = tf.contrib.layers.flatten(x)\n",
    "    logits = tf.layers.dense(x, num_classes)\n",
    "    return logits\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 16, 16, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "logits = model(X)\n",
    "\n",
    "loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(tf.one_hot(y, num_classes), logits=logits))\n",
    "\n",
    "predictions = tf.equal(tf.argmax(logits, 1), y)\n",
    "acc = tf.reduce_mean(tf.cast(predictions, tf.float32))\n",
    "\n",
    "train_indicies = np.arange(num_train)\n",
    "np.random.shuffle(train_indicies)\n",
    "\n",
    "val_indicies = np.arange(num_val)\n",
    "test_indicies = np.arange(num_test)\n",
    "\n",
    "test_predictions = tf.argmax(logits, 1)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def run_model(sess, train_step, batch_size, learning_rate, show_every):\n",
    "    print('training with batch_size: %d, learning_rate: %f'%(batch_size, learning_rate))\n",
    "    max_val_acc = .0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch %d:' % epoch)\n",
    "        for iter_i in range(num_train//batch_size):  \n",
    "            start_idx = (iter_i*batch_size)%num_train\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            _loss, _acc, _ = sess.run([loss, acc, train_step], feed_dict={\n",
    "                X: train_image[idx, :], y: train_label[idx]\n",
    "            })\n",
    "            if iter_i % show_every == 0:\n",
    "                print('iter: %d, loss: %f, acc: %f' % (iter_i, _loss, _acc))\n",
    "\n",
    "        #total_correct = []\n",
    "        for iter_i in range(num_val//val_batch_size):\n",
    "            start_idx = (iter_i * val_batch_size) % num_val\n",
    "            idx = val_indicies[start_idx:start_idx+val_batch_size]\n",
    "            val_acc = sess.run(acc, feed_dict={\n",
    "                X:val_image[idx, :], y: val_label[idx]\n",
    "            })\n",
    "            print('val set acc: %f'% val_acc)\n",
    "            #if (val_acc > max_val_acc):\n",
    "            #    max_val_acc = val_acc\n",
    "            #total_correct = total_correct + val_correct_predictions\n",
    "            \n",
    "#         if (val_acc >= 0.995):\n",
    "#             print('bingo!')\n",
    "#             total_test_predictions = []\n",
    "#             test_batch_size = 7000\n",
    "#             for test_iter in range(num_test//test_batch_size):\n",
    "#                 start_test_idx = (test_iter * test_batch_size)%num_test\n",
    "#                 test_idx = test_indicies[start_test_idx:start_test_idx+test_batch_size]\n",
    "#                 _test_predictions = sess.run(test_predictions, feed_dict={X:test_images[test_idx, :]})\n",
    "#                 total_test_predictions = np.concatenate((total_test_predictions,_test_predictions))\n",
    "            \n",
    "#             result = total_test_predictions\n",
    "#             with open('submission_%d.csv'%(epoch), 'w', newline='') as csvfile:\n",
    "#                 datawriter = csv.writer(csvfile, delimiter=',')\n",
    "#                 datawriter.writerow(['ImageId', 'Label'])\n",
    "#                 for i, predict_label in enumerate(result):\n",
    "#                     datawriter.writerow([i+1, predict_label.astype(np.uint8)])\n",
    "        \n",
    "#         save_path = \"../ckpt/epoch%d/model.ckpt\"%epoch\n",
    "#         saver.save(sess, save_path)\n",
    "    return max_val_acc\n",
    "#     print('predicting:')\n",
    "#     total_test_predictions = []\n",
    "#     test_batch_size = 7000\n",
    "#     for test_iter in range(num_test//test_batch_size):\n",
    "#         start_test_idx = (test_iter * test_batch_size)%num_test\n",
    "#         test_idx = test_indicies[start_test_idx:start_test_idx+test_batch_size]\n",
    "#         _test_predictions = sess.run(test_predictions, feed_dict={X:test_images[test_idx, :]})\n",
    "#         total_test_predictions = np.concatenate((total_test_predictions,_test_predictions))\n",
    "#     return total_test_predictions\n",
    "\n",
    "def test(sess):\n",
    "    submission = pd.read_csv('/mnt/data/cdiscount/sample_submission.csv', index_col='_id')\n",
    "    most_frequent_guess =1000018296\n",
    "    submission['category_id'] = most_frequent_guess \n",
    "\n",
    "    num_images_test = 1768182\n",
    "    with open('/mnt/data/cdiscount/test.bson', 'rb') as f, \\\n",
    "             concurrent.futures.ThreadPoolExecutor(num_cpus) as executor:\n",
    "\n",
    "        data = bson.decode_file_iter(f)\n",
    "        future_load = []\n",
    "\n",
    "        for i,d in enumerate(data):\n",
    "            if i >= num_images_test:\n",
    "                  break\n",
    "            future_load.append(executor.submit(load_image, d['imgs'][0]['picture'], d['_id'], bar))\n",
    "        \n",
    "            #print(\"Starting future processing\")\n",
    "        for future in concurrent.futures.as_completed(future_load):\n",
    "            x, _id = future.result()\n",
    "            x = np.reshape(x, [-1, 16, 16, 3])\n",
    "            _test_predictions = sess.run(test_predictions, feed_dict={X:x})\n",
    "            #print('prediction = %d' % _test_predictions)\n",
    "            y_cat = rev_labels[_test_predictions[0]]\n",
    "            #for i in range(100):\n",
    "                #print('y_cat = %d' % rev_labels[i])\n",
    "            #print('y_hat=%d' % y_cat)\n",
    "            if y_cat == -1:\n",
    "                y_cat = most_frequent_guess\n",
    "\n",
    "            bar.update()\n",
    "            submission.loc[_id, 'category_id'] = y_cat\n",
    "    submission.to_csv('new_submission.csv.gz', compression='gzip')\n",
    "\n",
    "batch_size_arr = [128]\n",
    "learning_rate_arr = [5e-5]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for batch_size in batch_size_arr:\n",
    "        for learning_rate in learning_rate_arr:\n",
    "            train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            val_acc = run_model(sess, train_step, batch_size, learning_rate, show_every=1000)\n",
    "            #print('best_val_acc: %f'%val_acc)\n",
    "    del images\n",
    "    test(sess)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
