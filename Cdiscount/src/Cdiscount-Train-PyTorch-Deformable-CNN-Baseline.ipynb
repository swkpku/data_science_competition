{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model, assemble_model_with_classifier\n",
    "from trainer.trainer import get_trainer\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch_deform_conv.layers import ConvOffset2D\n",
    "from torch_deform_conv.cnn import get_vgg11_bn, get_vgg11_bn_deform\n",
    "from torch_deform_conv.utils import transfer_weights\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# redirect print to file\n",
    "# import sys\n",
    "# sys.stdout = open(\"PyTorch-resnet34-log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'train_batch_size': 128, 'val_batch_size': 128,\n",
    "    'arch': 'vgg11_bn', 'pretrained': True,\n",
    "    'optimizer': 'Adam', 'learning_rate': 1e-4, 'decay_lr_freq': 4e4, 'weight_decay': 1e-5,\n",
    "    'resume': None,\n",
    "    'start_epoch': 0, 'epochs': 10,\n",
    "    'print_freq': 10, 'validate_freq': 7e4, 'save_freq': 1e3,\n",
    "    'best_val_prec1': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "train_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                      images_csv=\"train_images.csv\",\n",
    "                                      bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                      with_label=True,\n",
    "                                      resize=160)\n",
    "val_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                    images_csv=\"val_images.csv\",\n",
    "                                    bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                    with_label=True,\n",
    "                                    resize=160)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['val_batch_size'], shuffle=True, num_workers=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel (\n",
      "  (module): AssembledModel (\n",
      "    (model): Sequential (\n",
      "      (0): Sequential (\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): ReLU (inplace)\n",
      "        (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (6): ReLU (inplace)\n",
      "        (7): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (10): ReLU (inplace)\n",
      "        (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (13): ReLU (inplace)\n",
      "        (14): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (17): ReLU (inplace)\n",
      "        (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (20): ReLU (inplace)\n",
      "        (21): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (24): ReLU (inplace)\n",
      "        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (27): ReLU (inplace)\n",
      "        (28): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential (\n",
      "      (0): Linear (12800 -> 5270)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define base line cnn model\n",
    "#model = get_vgg11_bn()\n",
    "#model = models.__dict__[config['arch']](pretrained=False)\n",
    "model = get_vgg11_bn()\n",
    "\n",
    "model = assemble_model(model, -1, 12800, 5270)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Epoch: [0][0/77344]\tTime 27.574 (27.574)\tData 3.946 (3.946)\tLoss 8.8177 (8.8177)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][10/77344]\tTime 1.213 (3.548)\tData 0.006 (0.366)\tLoss 8.3564 (8.5310)\tPrec@1 2.344 (1.207)\tPrec@5 4.688 (3.551)\n",
      "Epoch: [0][20/77344]\tTime 1.226 (2.439)\tData 0.011 (0.195)\tLoss 7.7380 (8.2250)\tPrec@1 6.250 (2.307)\tPrec@5 12.500 (5.990)\n",
      "Epoch: [0][30/77344]\tTime 1.212 (2.044)\tData 0.007 (0.135)\tLoss 7.4419 (7.9778)\tPrec@1 5.469 (2.848)\tPrec@5 11.719 (6.930)\n",
      "Epoch: [0][40/77344]\tTime 1.223 (1.843)\tData 0.008 (0.104)\tLoss 7.1791 (7.7946)\tPrec@1 2.344 (3.182)\tPrec@5 14.062 (7.736)\n",
      "Epoch: [0][50/77344]\tTime 1.201 (1.720)\tData 0.008 (0.085)\tLoss 7.2481 (7.6578)\tPrec@1 7.812 (3.600)\tPrec@5 14.844 (8.395)\n",
      "Epoch: [0][60/77344]\tTime 1.214 (1.638)\tData 0.010 (0.073)\tLoss 7.0288 (7.5768)\tPrec@1 6.250 (3.778)\tPrec@5 12.500 (8.786)\n",
      "Epoch: [0][70/77344]\tTime 1.218 (1.579)\tData 0.008 (0.064)\tLoss 7.3221 (7.5126)\tPrec@1 7.031 (4.060)\tPrec@5 14.844 (9.254)\n",
      "Epoch: [0][80/77344]\tTime 1.210 (1.535)\tData 0.009 (0.057)\tLoss 6.8815 (7.4612)\tPrec@1 5.469 (4.263)\tPrec@5 11.719 (9.664)\n",
      "Epoch: [0][90/77344]\tTime 1.228 (1.501)\tData 0.007 (0.051)\tLoss 7.0076 (7.4053)\tPrec@1 7.031 (4.507)\tPrec@5 15.625 (10.062)\n",
      "Epoch: [0][100/77344]\tTime 1.231 (1.474)\tData 0.007 (0.047)\tLoss 6.8587 (7.3548)\tPrec@1 3.125 (4.680)\tPrec@5 8.594 (10.319)\n",
      "Epoch: [0][110/77344]\tTime 1.235 (1.452)\tData 0.007 (0.044)\tLoss 6.8443 (7.3051)\tPrec@1 4.688 (4.927)\tPrec@5 11.719 (10.656)\n",
      "Epoch: [0][120/77344]\tTime 1.205 (1.434)\tData 0.009 (0.041)\tLoss 6.8432 (7.2681)\tPrec@1 7.031 (5.043)\tPrec@5 13.281 (10.983)\n",
      "Epoch: [0][130/77344]\tTime 1.226 (1.418)\tData 0.010 (0.038)\tLoss 6.9038 (7.2279)\tPrec@1 3.906 (5.188)\tPrec@5 12.500 (11.236)\n",
      "Epoch: [0][140/77344]\tTime 1.226 (1.406)\tData 0.008 (0.036)\tLoss 6.3603 (7.1936)\tPrec@1 8.594 (5.236)\tPrec@5 17.188 (11.420)\n",
      "Epoch: [0][150/77344]\tTime 1.230 (1.394)\tData 0.010 (0.034)\tLoss 6.5224 (7.1553)\tPrec@1 9.375 (5.407)\tPrec@5 17.969 (11.683)\n",
      "Epoch: [0][160/77344]\tTime 1.236 (1.384)\tData 0.009 (0.033)\tLoss 6.5763 (7.1266)\tPrec@1 10.156 (5.561)\tPrec@5 18.750 (11.932)\n",
      "Epoch: [0][170/77344]\tTime 1.230 (1.375)\tData 0.008 (0.032)\tLoss 6.5559 (7.0938)\tPrec@1 8.594 (5.647)\tPrec@5 17.969 (12.203)\n",
      "Epoch: [0][180/77344]\tTime 1.221 (1.367)\tData 0.010 (0.030)\tLoss 6.5948 (7.0686)\tPrec@1 6.250 (5.715)\tPrec@5 15.625 (12.401)\n",
      "Epoch: [0][190/77344]\tTime 1.232 (1.360)\tData 0.008 (0.029)\tLoss 6.6133 (7.0366)\tPrec@1 5.469 (5.845)\tPrec@5 17.969 (12.713)\n",
      "Epoch: [0][200/77344]\tTime 1.222 (1.354)\tData 0.010 (0.028)\tLoss 6.6129 (7.0120)\tPrec@1 8.594 (5.955)\tPrec@5 17.969 (12.912)\n",
      "Epoch: [0][210/77344]\tTime 1.234 (1.348)\tData 0.015 (0.027)\tLoss 6.3915 (6.9909)\tPrec@1 10.938 (6.091)\tPrec@5 18.750 (13.085)\n",
      "Epoch: [0][220/77344]\tTime 1.230 (1.344)\tData 0.011 (0.027)\tLoss 6.5407 (6.9631)\tPrec@1 6.250 (6.211)\tPrec@5 17.969 (13.401)\n",
      "Epoch: [0][230/77344]\tTime 1.233 (1.339)\tData 0.009 (0.026)\tLoss 6.3676 (6.9351)\tPrec@1 10.156 (6.311)\tPrec@5 21.875 (13.711)\n",
      "Epoch: [0][240/77344]\tTime 1.237 (1.334)\tData 0.011 (0.025)\tLoss 6.3058 (6.9132)\tPrec@1 9.375 (6.490)\tPrec@5 21.094 (13.949)\n",
      "Epoch: [0][250/77344]\tTime 1.227 (1.331)\tData 0.009 (0.025)\tLoss 6.3616 (6.8893)\tPrec@1 10.156 (6.664)\tPrec@5 19.531 (14.246)\n",
      "Epoch: [0][260/77344]\tTime 1.229 (1.327)\tData 0.008 (0.024)\tLoss 5.6904 (6.8652)\tPrec@1 10.938 (6.801)\tPrec@5 21.875 (14.443)\n",
      "Epoch: [0][270/77344]\tTime 1.231 (1.324)\tData 0.011 (0.024)\tLoss 5.8441 (6.8395)\tPrec@1 17.969 (6.956)\tPrec@5 25.781 (14.740)\n",
      "Epoch: [0][280/77344]\tTime 1.244 (1.321)\tData 0.011 (0.023)\tLoss 6.4657 (6.8204)\tPrec@1 12.500 (7.101)\tPrec@5 21.094 (14.938)\n",
      "Epoch: [0][290/77344]\tTime 1.223 (1.318)\tData 0.010 (0.023)\tLoss 6.6592 (6.8002)\tPrec@1 8.594 (7.225)\tPrec@5 19.531 (15.171)\n",
      "Epoch: [0][300/77344]\tTime 1.249 (1.315)\tData 0.013 (0.022)\tLoss 6.3892 (6.7771)\tPrec@1 7.812 (7.392)\tPrec@5 15.625 (15.436)\n",
      "Epoch: [0][310/77344]\tTime 1.235 (1.312)\tData 0.009 (0.022)\tLoss 6.1376 (6.7583)\tPrec@1 7.031 (7.521)\tPrec@5 17.969 (15.650)\n",
      "Epoch: [0][320/77344]\tTime 1.224 (1.310)\tData 0.009 (0.021)\tLoss 6.0583 (6.7380)\tPrec@1 11.719 (7.684)\tPrec@5 23.438 (15.900)\n",
      "Epoch: [0][330/77344]\tTime 1.231 (1.308)\tData 0.009 (0.021)\tLoss 6.0032 (6.7178)\tPrec@1 15.625 (7.874)\tPrec@5 25.781 (16.158)\n",
      "Epoch: [0][340/77344]\tTime 1.244 (1.306)\tData 0.010 (0.021)\tLoss 6.0751 (6.7015)\tPrec@1 11.719 (7.975)\tPrec@5 23.438 (16.338)\n",
      "Epoch: [0][350/77344]\tTime 1.243 (1.304)\tData 0.013 (0.020)\tLoss 6.2847 (6.6860)\tPrec@1 17.969 (8.160)\tPrec@5 25.000 (16.533)\n",
      "Epoch: [0][360/77344]\tTime 1.227 (1.302)\tData 0.014 (0.020)\tLoss 6.0367 (6.6653)\tPrec@1 11.719 (8.345)\tPrec@5 19.531 (16.774)\n",
      "Epoch: [0][370/77344]\tTime 1.308 (1.300)\tData 0.010 (0.020)\tLoss 6.1637 (6.6473)\tPrec@1 8.594 (8.482)\tPrec@5 17.188 (16.975)\n",
      "Epoch: [0][380/77344]\tTime 1.239 (1.299)\tData 0.010 (0.020)\tLoss 6.1212 (6.6315)\tPrec@1 10.938 (8.614)\tPrec@5 21.094 (17.138)\n",
      "Epoch: [0][390/77344]\tTime 1.222 (1.297)\tData 0.012 (0.019)\tLoss 6.2575 (6.6129)\tPrec@1 14.062 (8.796)\tPrec@5 23.438 (17.375)\n",
      "Epoch: [0][400/77344]\tTime 1.249 (1.295)\tData 0.010 (0.019)\tLoss 6.4354 (6.5942)\tPrec@1 10.156 (8.952)\tPrec@5 19.531 (17.601)\n",
      "Epoch: [0][410/77344]\tTime 1.323 (1.294)\tData 0.010 (0.019)\tLoss 5.8999 (6.5767)\tPrec@1 13.281 (9.092)\tPrec@5 24.219 (17.777)\n",
      "Epoch: [0][420/77344]\tTime 1.243 (1.293)\tData 0.011 (0.019)\tLoss 5.7261 (6.5600)\tPrec@1 11.719 (9.219)\tPrec@5 26.562 (17.961)\n",
      "Epoch: [0][430/77344]\tTime 1.224 (1.292)\tData 0.011 (0.019)\tLoss 5.6963 (6.5489)\tPrec@1 18.750 (9.313)\tPrec@5 28.906 (18.087)\n",
      "Epoch: [0][440/77344]\tTime 1.207 (1.291)\tData 0.012 (0.019)\tLoss 6.1325 (6.5346)\tPrec@1 13.281 (9.400)\tPrec@5 25.781 (18.233)\n",
      "Epoch: [0][450/77344]\tTime 1.242 (1.289)\tData 0.010 (0.018)\tLoss 5.7335 (6.5176)\tPrec@1 14.844 (9.522)\tPrec@5 25.000 (18.390)\n",
      "Epoch: [0][460/77344]\tTime 1.231 (1.288)\tData 0.008 (0.018)\tLoss 5.9830 (6.5035)\tPrec@1 15.625 (9.624)\tPrec@5 23.438 (18.565)\n",
      "Epoch: [0][470/77344]\tTime 1.227 (1.287)\tData 0.015 (0.018)\tLoss 5.9171 (6.4900)\tPrec@1 13.281 (9.766)\tPrec@5 24.219 (18.768)\n",
      "Epoch: [0][480/77344]\tTime 1.232 (1.286)\tData 0.009 (0.018)\tLoss 5.9735 (6.4771)\tPrec@1 17.969 (9.862)\tPrec@5 25.000 (18.927)\n",
      "Epoch: [0][490/77344]\tTime 1.244 (1.285)\tData 0.009 (0.018)\tLoss 5.7750 (6.4614)\tPrec@1 17.188 (10.002)\tPrec@5 30.469 (19.105)\n",
      "Epoch: [0][500/77344]\tTime 1.234 (1.284)\tData 0.014 (0.018)\tLoss 6.0106 (6.4509)\tPrec@1 17.188 (10.097)\tPrec@5 27.344 (19.241)\n",
      "Epoch: [0][510/77344]\tTime 1.215 (1.283)\tData 0.012 (0.018)\tLoss 5.8814 (6.4364)\tPrec@1 11.719 (10.222)\tPrec@5 22.656 (19.423)\n",
      "Epoch: [0][520/77344]\tTime 1.231 (1.282)\tData 0.013 (0.017)\tLoss 5.6061 (6.4230)\tPrec@1 21.094 (10.341)\tPrec@5 35.156 (19.579)\n",
      "Epoch: [0][530/77344]\tTime 1.245 (1.281)\tData 0.009 (0.017)\tLoss 5.8137 (6.4127)\tPrec@1 12.500 (10.448)\tPrec@5 20.312 (19.717)\n",
      "Epoch: [0][540/77344]\tTime 1.249 (1.280)\tData 0.014 (0.017)\tLoss 5.5246 (6.4020)\tPrec@1 16.406 (10.556)\tPrec@5 30.469 (19.865)\n",
      "Epoch: [0][550/77344]\tTime 1.245 (1.280)\tData 0.011 (0.017)\tLoss 5.6928 (6.3912)\tPrec@1 19.531 (10.623)\tPrec@5 29.688 (19.976)\n",
      "Epoch: [0][560/77344]\tTime 1.252 (1.279)\tData 0.014 (0.017)\tLoss 6.2138 (6.3786)\tPrec@1 17.188 (10.720)\tPrec@5 26.562 (20.134)\n",
      "Epoch: [0][570/77344]\tTime 1.224 (1.278)\tData 0.009 (0.017)\tLoss 5.7200 (6.3690)\tPrec@1 17.969 (10.813)\tPrec@5 32.031 (20.255)\n",
      "Epoch: [0][580/77344]\tTime 1.232 (1.277)\tData 0.009 (0.017)\tLoss 5.9012 (6.3584)\tPrec@1 13.281 (10.897)\tPrec@5 28.906 (20.429)\n",
      "Epoch: [0][590/77344]\tTime 1.231 (1.277)\tData 0.010 (0.017)\tLoss 5.4808 (6.3450)\tPrec@1 16.406 (11.004)\tPrec@5 31.250 (20.594)\n",
      "Epoch: [0][600/77344]\tTime 1.245 (1.276)\tData 0.009 (0.016)\tLoss 5.5111 (6.3307)\tPrec@1 17.188 (11.114)\tPrec@5 28.906 (20.773)\n",
      "Epoch: [0][610/77344]\tTime 1.234 (1.275)\tData 0.012 (0.016)\tLoss 5.5295 (6.3188)\tPrec@1 16.406 (11.220)\tPrec@5 31.250 (20.926)\n",
      "Epoch: [0][620/77344]\tTime 1.326 (1.275)\tData 0.009 (0.016)\tLoss 5.8873 (6.3072)\tPrec@1 11.719 (11.331)\tPrec@5 25.000 (21.101)\n",
      "Epoch: [0][630/77344]\tTime 1.231 (1.274)\tData 0.009 (0.016)\tLoss 5.7329 (6.2980)\tPrec@1 18.750 (11.438)\tPrec@5 28.906 (21.231)\n",
      "Epoch: [0][640/77344]\tTime 1.225 (1.273)\tData 0.017 (0.016)\tLoss 5.6643 (6.2868)\tPrec@1 15.625 (11.526)\tPrec@5 25.000 (21.372)\n",
      "Epoch: [0][650/77344]\tTime 1.227 (1.273)\tData 0.015 (0.016)\tLoss 5.8505 (6.2793)\tPrec@1 14.062 (11.594)\tPrec@5 32.812 (21.485)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][660/77344]\tTime 1.221 (1.272)\tData 0.009 (0.016)\tLoss 5.8275 (6.2699)\tPrec@1 10.938 (11.657)\tPrec@5 21.094 (21.597)\n",
      "Epoch: [0][670/77344]\tTime 1.239 (1.272)\tData 0.009 (0.016)\tLoss 5.3448 (6.2575)\tPrec@1 18.750 (11.747)\tPrec@5 31.250 (21.755)\n",
      "Epoch: [0][680/77344]\tTime 1.225 (1.271)\tData 0.009 (0.016)\tLoss 5.3483 (6.2440)\tPrec@1 18.750 (11.864)\tPrec@5 35.938 (21.917)\n",
      "Epoch: [0][690/77344]\tTime 1.231 (1.271)\tData 0.014 (0.016)\tLoss 5.4893 (6.2334)\tPrec@1 21.875 (11.952)\tPrec@5 34.375 (22.034)\n",
      "Epoch: [0][700/77344]\tTime 1.243 (1.270)\tData 0.018 (0.016)\tLoss 5.4468 (6.2247)\tPrec@1 18.750 (12.043)\tPrec@5 34.375 (22.169)\n",
      "Epoch: [0][710/77344]\tTime 1.232 (1.270)\tData 0.009 (0.016)\tLoss 5.2205 (6.2154)\tPrec@1 19.531 (12.100)\tPrec@5 33.594 (22.277)\n",
      "Epoch: [0][720/77344]\tTime 1.226 (1.269)\tData 0.011 (0.016)\tLoss 6.0006 (6.2042)\tPrec@1 17.188 (12.200)\tPrec@5 26.562 (22.406)\n",
      "Epoch: [0][730/77344]\tTime 1.216 (1.269)\tData 0.011 (0.016)\tLoss 5.5288 (6.1930)\tPrec@1 18.750 (12.281)\tPrec@5 31.250 (22.528)\n",
      "Epoch: [0][740/77344]\tTime 1.234 (1.268)\tData 0.012 (0.015)\tLoss 5.3772 (6.1815)\tPrec@1 21.094 (12.389)\tPrec@5 30.469 (22.677)\n",
      "Epoch: [0][750/77344]\tTime 1.213 (1.268)\tData 0.014 (0.015)\tLoss 4.7730 (6.1709)\tPrec@1 17.969 (12.472)\tPrec@5 41.406 (22.829)\n",
      "Epoch: [0][760/77344]\tTime 1.231 (1.267)\tData 0.011 (0.015)\tLoss 5.1772 (6.1607)\tPrec@1 21.094 (12.570)\tPrec@5 35.938 (22.972)\n",
      "Epoch: [0][770/77344]\tTime 1.234 (1.267)\tData 0.009 (0.015)\tLoss 4.9843 (6.1511)\tPrec@1 21.875 (12.649)\tPrec@5 35.938 (23.106)\n",
      "Epoch: [0][780/77344]\tTime 1.244 (1.266)\tData 0.011 (0.015)\tLoss 5.4588 (6.1417)\tPrec@1 17.969 (12.736)\tPrec@5 32.031 (23.220)\n",
      "Epoch: [0][790/77344]\tTime 1.234 (1.266)\tData 0.009 (0.015)\tLoss 5.2244 (6.1336)\tPrec@1 17.188 (12.813)\tPrec@5 32.031 (23.321)\n",
      "Epoch: [0][800/77344]\tTime 1.229 (1.265)\tData 0.010 (0.015)\tLoss 5.5483 (6.1263)\tPrec@1 16.406 (12.887)\tPrec@5 31.250 (23.431)\n",
      "Epoch: [0][810/77344]\tTime 1.236 (1.265)\tData 0.010 (0.015)\tLoss 5.6170 (6.1188)\tPrec@1 15.625 (12.959)\tPrec@5 35.156 (23.530)\n",
      "Epoch: [0][820/77344]\tTime 1.249 (1.265)\tData 0.010 (0.015)\tLoss 5.6776 (6.1108)\tPrec@1 15.625 (13.035)\tPrec@5 28.125 (23.634)\n",
      "Epoch: [0][830/77344]\tTime 1.224 (1.265)\tData 0.010 (0.015)\tLoss 5.0866 (6.1016)\tPrec@1 21.094 (13.118)\tPrec@5 36.719 (23.769)\n",
      "Epoch: [0][840/77344]\tTime 1.218 (1.264)\tData 0.011 (0.015)\tLoss 5.5349 (6.0932)\tPrec@1 16.406 (13.181)\tPrec@5 33.594 (23.890)\n",
      "Epoch: [0][850/77344]\tTime 1.225 (1.264)\tData 0.009 (0.015)\tLoss 4.8343 (6.0842)\tPrec@1 20.312 (13.261)\tPrec@5 33.594 (24.009)\n",
      "Epoch: [0][860/77344]\tTime 1.252 (1.264)\tData 0.009 (0.015)\tLoss 5.0276 (6.0752)\tPrec@1 22.656 (13.344)\tPrec@5 37.500 (24.113)\n",
      "Epoch: [0][870/77344]\tTime 1.246 (1.263)\tData 0.015 (0.015)\tLoss 5.1616 (6.0665)\tPrec@1 24.219 (13.418)\tPrec@5 37.500 (24.226)\n",
      "Epoch: [0][880/77344]\tTime 1.221 (1.263)\tData 0.012 (0.015)\tLoss 5.5959 (6.0583)\tPrec@1 21.875 (13.499)\tPrec@5 28.125 (24.330)\n",
      "Epoch: [0][890/77344]\tTime 1.230 (1.263)\tData 0.014 (0.015)\tLoss 5.2941 (6.0506)\tPrec@1 23.438 (13.579)\tPrec@5 38.281 (24.432)\n",
      "Epoch: [0][900/77344]\tTime 1.229 (1.262)\tData 0.012 (0.015)\tLoss 5.4246 (6.0440)\tPrec@1 19.531 (13.644)\tPrec@5 35.156 (24.525)\n",
      "Epoch: [0][910/77344]\tTime 1.228 (1.262)\tData 0.010 (0.015)\tLoss 5.4251 (6.0365)\tPrec@1 17.969 (13.710)\tPrec@5 27.344 (24.631)\n",
      "Epoch: [0][920/77344]\tTime 1.246 (1.262)\tData 0.009 (0.015)\tLoss 5.5513 (6.0270)\tPrec@1 18.750 (13.787)\tPrec@5 34.375 (24.759)\n",
      "Epoch: [0][930/77344]\tTime 1.246 (1.261)\tData 0.013 (0.014)\tLoss 5.7514 (6.0187)\tPrec@1 14.062 (13.869)\tPrec@5 24.219 (24.865)\n",
      "Epoch: [0][940/77344]\tTime 1.248 (1.261)\tData 0.011 (0.014)\tLoss 5.2322 (6.0109)\tPrec@1 18.750 (13.940)\tPrec@5 28.125 (24.960)\n",
      "Epoch: [0][950/77344]\tTime 1.237 (1.261)\tData 0.010 (0.014)\tLoss 5.3326 (6.0026)\tPrec@1 15.625 (14.011)\tPrec@5 33.594 (25.055)\n",
      "Epoch: [0][960/77344]\tTime 1.226 (1.261)\tData 0.011 (0.014)\tLoss 5.1741 (5.9969)\tPrec@1 13.281 (14.051)\tPrec@5 32.812 (25.120)\n",
      "Epoch: [0][970/77344]\tTime 1.244 (1.260)\tData 0.009 (0.014)\tLoss 5.4874 (5.9909)\tPrec@1 17.188 (14.103)\tPrec@5 30.469 (25.197)\n",
      "Epoch: [0][980/77344]\tTime 1.245 (1.260)\tData 0.010 (0.014)\tLoss 5.6549 (5.9848)\tPrec@1 21.875 (14.168)\tPrec@5 28.906 (25.276)\n",
      "Epoch: [0][990/77344]\tTime 1.228 (1.260)\tData 0.014 (0.014)\tLoss 5.5267 (5.9785)\tPrec@1 17.969 (14.241)\tPrec@5 31.250 (25.378)\n",
      "Epoch: [0][1000/77344]\tTime 1.223 (1.260)\tData 0.010 (0.014)\tLoss 4.8921 (5.9698)\tPrec@1 21.875 (14.311)\tPrec@5 35.156 (25.470)\n",
      "Epoch: [0][1010/77344]\tTime 1.331 (1.260)\tData 0.010 (0.016)\tLoss 5.3274 (5.9626)\tPrec@1 25.781 (14.401)\tPrec@5 37.500 (25.571)\n",
      "Epoch: [0][1020/77344]\tTime 1.225 (1.260)\tData 0.010 (0.016)\tLoss 4.7247 (5.9550)\tPrec@1 25.781 (14.483)\tPrec@5 39.062 (25.673)\n",
      "Epoch: [0][1030/77344]\tTime 1.227 (1.260)\tData 0.015 (0.016)\tLoss 4.6589 (5.9481)\tPrec@1 28.125 (14.566)\tPrec@5 43.750 (25.767)\n",
      "Epoch: [0][1040/77344]\tTime 1.236 (1.260)\tData 0.011 (0.016)\tLoss 4.4181 (5.9405)\tPrec@1 32.812 (14.637)\tPrec@5 48.438 (25.874)\n",
      "Epoch: [0][1050/77344]\tTime 1.229 (1.259)\tData 0.022 (0.016)\tLoss 4.9228 (5.9332)\tPrec@1 21.875 (14.718)\tPrec@5 37.500 (25.979)\n",
      "Epoch: [0][1060/77344]\tTime 1.245 (1.259)\tData 0.009 (0.016)\tLoss 5.0818 (5.9264)\tPrec@1 19.531 (14.777)\tPrec@5 38.281 (26.063)\n",
      "Epoch: [0][1070/77344]\tTime 1.236 (1.259)\tData 0.010 (0.016)\tLoss 4.9255 (5.9204)\tPrec@1 22.656 (14.839)\tPrec@5 39.844 (26.158)\n",
      "Epoch: [0][1080/77344]\tTime 1.229 (1.259)\tData 0.014 (0.016)\tLoss 4.6183 (5.9130)\tPrec@1 23.438 (14.901)\tPrec@5 44.531 (26.250)\n",
      "Epoch: [0][1090/77344]\tTime 1.264 (1.259)\tData 0.011 (0.016)\tLoss 5.2587 (5.9053)\tPrec@1 25.000 (14.983)\tPrec@5 36.719 (26.359)\n",
      "Epoch: [0][1100/77344]\tTime 1.228 (1.258)\tData 0.013 (0.016)\tLoss 4.8098 (5.8970)\tPrec@1 25.000 (15.081)\tPrec@5 38.281 (26.466)\n",
      "Epoch: [0][1110/77344]\tTime 1.227 (1.258)\tData 0.012 (0.016)\tLoss 4.6440 (5.8889)\tPrec@1 20.312 (15.155)\tPrec@5 41.406 (26.576)\n",
      "Epoch: [0][1120/77344]\tTime 1.233 (1.258)\tData 0.012 (0.016)\tLoss 5.2337 (5.8817)\tPrec@1 15.625 (15.223)\tPrec@5 35.156 (26.671)\n",
      "Epoch: [0][1130/77344]\tTime 1.226 (1.258)\tData 0.012 (0.016)\tLoss 5.0580 (5.8753)\tPrec@1 21.094 (15.281)\tPrec@5 33.594 (26.749)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "KeyboardInterrupt\n",
      "Process Process-10:\n",
      "Process Process-7:\n",
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9852eb190a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data_science_competition/Cdiscount/src/trainer/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data_science_competition/Cdiscount/src/trainer/trainer.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, epoch, start_iter)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mprec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mtop5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# get trainer\n",
    "Trainer = get_trainer(train_dataloader, val_dataloader, model, criterion, config)\n",
    "\n",
    "# Run!\n",
    "Trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
