{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import bson\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiso/tensorflow/lib/python3.5/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_images = 9900946, num_val_images = 2470347, num_test_images = 3095080\n"
     ]
    }
   ],
   "source": [
    "def make_category_tables():\n",
    "    cat2idx = {}\n",
    "    idx2cat = {}\n",
    "    for ir in categories_df.itertuples():\n",
    "        category_id = ir[0]\n",
    "        category_idx = ir[4]\n",
    "        cat2idx[category_id] = category_idx\n",
    "        idx2cat[category_idx] = category_id\n",
    "    return cat2idx, idx2cat\n",
    "\n",
    "categories_df = pd.read_csv(\"categories.csv\", index_col=0)\n",
    "cat2idx, idx2cat = make_category_tables()\n",
    "\n",
    "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"train_images.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"val_images.csv\", index_col=0)\n",
    "\n",
    "test_offsets_df = pd.read_csv(\"test_offsets.csv\", index_col=0)\n",
    "test_images_df = pd.read_csv(\"test_images.csv\", index_col=0)\n",
    "\n",
    "num_train_images = len(train_images_df)\n",
    "num_val_images = len(val_images_df)\n",
    "num_test_images = len(test_images_df)\n",
    "print('num_train_images = %d, num_val_images = %d, num_test_images = %d' % (num_train_images, num_val_images, num_test_images))\n",
    "\n",
    "data_dir = \"/mnt/data/cdiscount/\"\n",
    "\n",
    "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
    "test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
    "\n",
    "train_bson_file = open(train_bson_path, \"rb\")\n",
    "test_bson_file = open(test_bson_path, \"rb\")\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_shape = (128, 128)\n",
    "num_class = 5270\n",
    "\n",
    "def get_batch(bson_file, images_df, offsets_df, index_array, with_labels):\n",
    "    batch_x = np.zeros((len(index_array),) + image_shape + (3, ), dtype=np.float16)\n",
    "    batch_id = np.zeros(len(index_array), dtype=np.uint32)\n",
    "    if with_labels:\n",
    "        batch_y = np.zeros((len(batch_x), num_class), dtype=np.float16)\n",
    "\n",
    "    for i, j in enumerate(index_array):\n",
    "        image_row = images_df.iloc[j]\n",
    "        product_id = image_row[\"product_id\"]\n",
    "        offset_row = offsets_df.loc[product_id]\n",
    "\n",
    "        # Read this product's data from the BSON file.\n",
    "        bson_file.seek(offset_row[\"offset\"])\n",
    "        item_data = bson_file.read(offset_row[\"length\"])\n",
    "\n",
    "        # Grab the image from the product.\n",
    "        item = bson.BSON.decode(item_data)\n",
    "        img_idx = image_row[\"img_idx\"]\n",
    "        bson_img = item[\"imgs\"][img_idx][\"picture\"]\n",
    "\n",
    "        # Preprocess the image.\n",
    "        img = Image.open(io.BytesIO(bson_img))\n",
    "        img = img.resize(image_shape)\n",
    "        x = np.asarray(img, dtype=np.float16)\n",
    "        \n",
    "        #x = self.image_data_generator.random_transform(x)\n",
    "        #x = self.image_data_generator.standardize(x)\n",
    "\n",
    "        # Add the image and the label to the batch (one-hot encoded).\n",
    "        batch_x[i] = x\n",
    "        batch_id[i] = product_id\n",
    "        if with_labels:\n",
    "            batch_y[i, image_row[\"category_idx\"]] = 1\n",
    "\n",
    "    if with_labels:\n",
    "        return batch_x, batch_y, batch_id\n",
    "    else:\n",
    "        return batch_x, batch_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index_array_all = np.arange(num_train_images)\n",
    "np.random.shuffle(train_index_array_all)\n",
    "\n",
    "val_index_array_all = np.arange(num_val_images)\n",
    "np.random.shuffle(val_index_array_all)\n",
    "\n",
    "train_batch_index_array\n",
    "\n",
    "train_batch_x, train_batch_y, _ = get_batch(train_bson_file, train_images_df, train_offsets_df, train_batch_index_array, with_labels=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
