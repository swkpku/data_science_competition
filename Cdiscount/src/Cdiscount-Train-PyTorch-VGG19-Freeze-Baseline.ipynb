{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model, assemble_model_with_classifier, cut_and_concatenate_model\n",
    "from model.utils import freeze_layers\n",
    "from trainer.trainer import get_trainer\n",
    "\n",
    "from torch_deform_conv.layers import ConvOffset2D\n",
    "from torch_deform_conv.cnn import get_vgg11_bn_deform\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# redirect print to file\n",
    "# import sys\n",
    "# sys.stdout = open(\"PyTorch-resnet34-log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'train_batch_size': 128, 'val_batch_size': 128,\n",
    "    'arch': 'vgg19_bn', 'pretrained': True,\n",
    "    'optimizer': 'Adam', 'learning_rate': 1e-3, 'decay_lr_freq': 4e4, 'weight_decay': 1e-5,\n",
    "    'resume': None,\n",
    "    'start_epoch': 0, 'epochs': 10,\n",
    "    'print_freq': 10, 'validate_freq': 1e3, 'save_freq': 1e4,\n",
    "    'best_val_prec1': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n",
      "=> using pre-trained model 'vgg19_bn'\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "DataParallel (\n",
      "  (module): AssembledModel (\n",
      "    (model): Sequential (\n",
      "      (0): Sequential (\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): ReLU (inplace)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (5): ReLU (inplace)\n",
      "        (6): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (9): ReLU (inplace)\n",
      "        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (12): ReLU (inplace)\n",
      "        (13): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (16): ReLU (inplace)\n",
      "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (19): ReLU (inplace)\n",
      "        (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (22): ReLU (inplace)\n",
      "        (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (25): ReLU (inplace)\n",
      "        (26): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (29): ReLU (inplace)\n",
      "        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (32): ReLU (inplace)\n",
      "        (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (35): ReLU (inplace)\n",
      "        (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (38): ReLU (inplace)\n",
      "        (39): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (42): ReLU (inplace)\n",
      "        (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (45): ReLU (inplace)\n",
      "        (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (48): ReLU (inplace)\n",
      "        (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (51): ReLU (inplace)\n",
      "        (52): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential (\n",
      "      (0): Linear (12800 -> 5270)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "train_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                      images_csv=\"train_images.csv\",\n",
    "                                      bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                      with_label=True,\n",
    "                                      resize=160)\n",
    "val_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                    images_csv=\"val_images.csv\",\n",
    "                                    bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                    with_label=True,\n",
    "                                    resize=160)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['val_batch_size'], shuffle=True, num_workers=6)\n",
    "\n",
    "# define model\n",
    "print(\"=> using pre-trained model '{}'\".format(config['arch']))\n",
    "model = models.__dict__[config['arch']](pretrained=config['pretrained'])\n",
    "\n",
    "# model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "# model.add_module('classifier', torch.nn.Linear(in_features=2048, out_features=5270))\n",
    "\n",
    "# freeze layers except last block\n",
    "for name, module in model.named_children():\n",
    "    if name == 'features':\n",
    "        for subname, submodule in module.named_children():\n",
    "            if subname in [str(i) for i in range(40)]:\n",
    "                print(submodule)\n",
    "                for param in submodule.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "\n",
    "classifier_layer = [\n",
    "    torch.nn.Linear(in_features=12800, out_features=5270)\n",
    "]\n",
    "\n",
    "classifier = torch.nn.Sequential(*classifier_layer)\n",
    "\n",
    "model = assemble_model_with_classifier(model, -1, classifier)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Epoch: [0][0/77359]\tTime 20.469 (20.469)\tData 4.199 (4.199)\tLoss 8.5981 (8.5981)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][10/77359]\tTime 0.940 (2.701)\tData 0.012 (0.395)\tLoss 6.9101 (7.5569)\tPrec@1 6.250 (4.830)\tPrec@5 14.062 (10.298)\n",
      "Epoch: [0][20/77359]\tTime 0.938 (1.858)\tData 0.012 (0.213)\tLoss 6.7617 (7.2380)\tPrec@1 9.375 (6.882)\tPrec@5 20.312 (14.211)\n",
      "Epoch: [0][30/77359]\tTime 0.939 (1.561)\tData 0.022 (0.149)\tLoss 6.1159 (6.9435)\tPrec@1 17.969 (8.795)\tPrec@5 30.469 (17.692)\n",
      "Epoch: [0][40/77359]\tTime 0.929 (1.409)\tData 0.011 (0.116)\tLoss 6.0619 (6.7569)\tPrec@1 14.062 (10.194)\tPrec@5 27.344 (20.179)\n",
      "Epoch: [0][50/77359]\tTime 0.923 (1.315)\tData 0.014 (0.096)\tLoss 6.1037 (6.5852)\tPrec@1 14.844 (11.550)\tPrec@5 25.781 (22.212)\n",
      "Epoch: [0][60/77359]\tTime 0.940 (1.252)\tData 0.014 (0.083)\tLoss 6.0413 (6.4591)\tPrec@1 10.938 (12.398)\tPrec@5 28.906 (23.770)\n",
      "Epoch: [0][70/77359]\tTime 0.951 (1.208)\tData 0.012 (0.073)\tLoss 5.7897 (6.3240)\tPrec@1 16.406 (13.567)\tPrec@5 26.562 (25.352)\n",
      "Epoch: [0][80/77359]\tTime 0.943 (1.174)\tData 0.015 (0.066)\tLoss 5.6743 (6.2294)\tPrec@1 20.312 (14.111)\tPrec@5 38.281 (26.312)\n",
      "Epoch: [0][90/77359]\tTime 0.936 (1.148)\tData 0.015 (0.060)\tLoss 5.0936 (6.1422)\tPrec@1 22.656 (14.827)\tPrec@5 36.719 (27.155)\n",
      "Epoch: [0][100/77359]\tTime 0.946 (1.127)\tData 0.012 (0.055)\tLoss 5.3323 (6.0642)\tPrec@1 19.531 (15.246)\tPrec@5 35.156 (27.970)\n",
      "Epoch: [0][110/77359]\tTime 0.940 (1.110)\tData 0.011 (0.052)\tLoss 5.6231 (6.0055)\tPrec@1 17.188 (15.639)\tPrec@5 32.812 (28.632)\n",
      "Epoch: [0][120/77359]\tTime 0.936 (1.095)\tData 0.018 (0.049)\tLoss 5.4177 (5.9570)\tPrec@1 18.750 (16.012)\tPrec@5 35.156 (29.197)\n",
      "Epoch: [0][130/77359]\tTime 0.934 (1.083)\tData 0.015 (0.046)\tLoss 5.4206 (5.9056)\tPrec@1 13.281 (16.323)\tPrec@5 28.906 (29.652)\n",
      "Epoch: [0][140/77359]\tTime 0.936 (1.073)\tData 0.013 (0.044)\tLoss 5.6263 (5.8615)\tPrec@1 16.406 (16.645)\tPrec@5 35.156 (30.192)\n",
      "Epoch: [0][150/77359]\tTime 0.963 (1.064)\tData 0.016 (0.042)\tLoss 5.2249 (5.8172)\tPrec@1 21.875 (16.986)\tPrec@5 33.594 (30.660)\n",
      "Epoch: [0][160/77359]\tTime 0.944 (1.056)\tData 0.033 (0.040)\tLoss 5.1661 (5.7605)\tPrec@1 20.312 (17.551)\tPrec@5 39.844 (31.303)\n",
      "Epoch: [0][170/77359]\tTime 0.927 (1.049)\tData 0.018 (0.039)\tLoss 5.0499 (5.7129)\tPrec@1 26.562 (17.932)\tPrec@5 39.844 (31.894)\n",
      "Epoch: [0][180/77359]\tTime 0.943 (1.043)\tData 0.017 (0.038)\tLoss 4.7265 (5.6682)\tPrec@1 23.438 (18.228)\tPrec@5 36.719 (32.407)\n",
      "Epoch: [0][190/77359]\tTime 0.938 (1.038)\tData 0.015 (0.036)\tLoss 5.1538 (5.6313)\tPrec@1 19.531 (18.627)\tPrec@5 35.156 (32.886)\n",
      "Epoch: [0][200/77359]\tTime 0.939 (1.033)\tData 0.018 (0.035)\tLoss 4.7804 (5.5946)\tPrec@1 26.562 (18.929)\tPrec@5 39.062 (33.256)\n",
      "Epoch: [0][210/77359]\tTime 0.928 (1.028)\tData 0.015 (0.034)\tLoss 4.7169 (5.5660)\tPrec@1 26.562 (19.135)\tPrec@5 45.312 (33.557)\n",
      "Epoch: [0][220/77359]\tTime 0.947 (1.025)\tData 0.014 (0.033)\tLoss 4.4590 (5.5293)\tPrec@1 32.031 (19.514)\tPrec@5 50.000 (34.014)\n",
      "Epoch: [0][230/77359]\tTime 0.945 (1.021)\tData 0.017 (0.033)\tLoss 4.9254 (5.5040)\tPrec@1 22.656 (19.707)\tPrec@5 43.750 (34.348)\n",
      "Epoch: [0][240/77359]\tTime 0.955 (1.018)\tData 0.014 (0.032)\tLoss 5.1393 (5.4707)\tPrec@1 21.875 (20.027)\tPrec@5 38.281 (34.735)\n",
      "Epoch: [0][250/77359]\tTime 0.932 (1.015)\tData 0.016 (0.031)\tLoss 4.6710 (5.4410)\tPrec@1 25.781 (20.263)\tPrec@5 43.750 (35.069)\n",
      "Epoch: [0][260/77359]\tTime 0.944 (1.012)\tData 0.015 (0.030)\tLoss 4.5103 (5.4118)\tPrec@1 27.344 (20.507)\tPrec@5 50.000 (35.447)\n",
      "Epoch: [0][270/77359]\tTime 0.948 (1.010)\tData 0.016 (0.030)\tLoss 4.9990 (5.3865)\tPrec@1 23.438 (20.707)\tPrec@5 42.969 (35.733)\n",
      "Epoch: [0][280/77359]\tTime 0.942 (1.007)\tData 0.012 (0.029)\tLoss 4.9728 (5.3639)\tPrec@1 26.562 (20.891)\tPrec@5 42.969 (36.029)\n",
      "Epoch: [0][290/77359]\tTime 0.932 (1.005)\tData 0.014 (0.029)\tLoss 4.2385 (5.3431)\tPrec@1 30.469 (21.070)\tPrec@5 47.656 (36.265)\n",
      "Epoch: [0][300/77359]\tTime 0.951 (1.003)\tData 0.020 (0.028)\tLoss 4.8732 (5.3237)\tPrec@1 25.781 (21.224)\tPrec@5 43.750 (36.537)\n",
      "Epoch: [0][310/77359]\tTime 0.920 (1.001)\tData 0.019 (0.028)\tLoss 4.9192 (5.2971)\tPrec@1 30.469 (21.478)\tPrec@5 43.750 (36.882)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "Process Process-6:\n",
      "Process Process-2:\n",
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9852eb190a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data_science_competition/Cdiscount/src/trainer/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data_science_competition/Cdiscount/src/trainer/trainer.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, epoch, start_iter)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mprec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mtop5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# get trainer\n",
    "Trainer = get_trainer(train_dataloader, val_dataloader, model, criterion, config)\n",
    "\n",
    "# Run!\n",
    "Trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
