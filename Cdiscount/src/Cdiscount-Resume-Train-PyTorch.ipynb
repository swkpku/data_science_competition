{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model, assemble_model_with_classifier\n",
    "from trainer.trainer import get_trainer\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# redirect print to file\n",
    "# import sys\n",
    "# sys.stdout = open(\"PyTorch-resnet34-log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = \"vgg19_bn_checkpoint_epoch_0_iter_52000.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0] iter: [52000]\tLoss 1.4517 (1.4517)\tPrec@1 67.969 (67.969)\tPrec@5 85.156 (85.156)\n",
      "{'train_batch_size': 128, 'print_freq': 10, 'decay_lr_freq': 40000.0, 'save_freq': 1000.0, 'learning_rate': 0.0001, 'best_val_prec1': 0, 'weight_decay': 1e-05, 'pretrained': True, 'validate_freq': 70000.0, 'resume': 'vgg19_bn_checkpoint_epoch_0_iter_52000.pth.tar', 'optimizer': 'Adam', 'epochs': 10, 'arch': 'vgg19_bn', 'start_epoch': 0, 'val_batch_size': 128}\n"
     ]
    }
   ],
   "source": [
    "#checkpoint = torch.load(checkpoint_file)\n",
    "checkpoint = torch.load(checkpoint_file, map_location=lambda storage, loc: storage) # load on CPU to save some GPU memory\n",
    "\n",
    "print('Epoch: [{0}] iter: [{1}]\\t'\n",
    "      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "          checkpoint['epoch'], checkpoint['iter'],\n",
    "          loss=checkpoint['loss'],\n",
    "          top1=checkpoint['top1'],\n",
    "          top5=checkpoint['top5']))\n",
    "\n",
    "config = checkpoint['config']\n",
    "\n",
    "# set to resume mode\n",
    "config['resume'] = checkpoint_file\n",
    "config['learning_rate'] = 1e-4\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n",
      "=> using pre-trained model 'vgg19_bn'\n",
      "DataParallel (\n",
      "  (module): AssembledModel (\n",
      "    (model): Sequential (\n",
      "      (0): Sequential (\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): ReLU (inplace)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (5): ReLU (inplace)\n",
      "        (6): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (9): ReLU (inplace)\n",
      "        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (12): ReLU (inplace)\n",
      "        (13): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (16): ReLU (inplace)\n",
      "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (19): ReLU (inplace)\n",
      "        (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (22): ReLU (inplace)\n",
      "        (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (25): ReLU (inplace)\n",
      "        (26): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (29): ReLU (inplace)\n",
      "        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (32): ReLU (inplace)\n",
      "        (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (35): ReLU (inplace)\n",
      "        (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (38): ReLU (inplace)\n",
      "        (39): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (42): ReLU (inplace)\n",
      "        (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (45): ReLU (inplace)\n",
      "        (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (48): ReLU (inplace)\n",
      "        (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (51): ReLU (inplace)\n",
      "        (52): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential (\n",
      "      (0): Linear (12800 -> 5270)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=> loading checkpoint 'vgg19_bn_checkpoint_epoch_0_iter_52000.pth.tar'\n",
      "=> loaded checkpoint 'vgg19_bn_checkpoint_epoch_0_iter_52000.pth.tar' (epoch 0) (iter 52000)\n",
      "start training\n",
      "adjust learning rate, decay_rate = 1\n",
      "Epoch: [0][52000/77344]\tTime 34.023 (34.023)\tData 3.912 (3.912)\tLoss 1.3824 (1.3824)\tPrec@1 67.969 (67.969)\tPrec@5 88.281 (88.281)\n",
      "Epoch: [0][52010/77344]\tTime 2.710 (8.683)\tData 0.013 (3.553)\tLoss 1.3944 (1.5675)\tPrec@1 67.969 (65.554)\tPrec@5 85.938 (83.381)\n",
      "Epoch: [0][52020/77344]\tTime 2.773 (5.863)\tData 0.010 (1.865)\tLoss 1.5998 (1.5981)\tPrec@1 69.531 (65.625)\tPrec@5 86.719 (83.445)\n",
      "Epoch: [0][52030/77344]\tTime 2.778 (4.864)\tData 0.007 (1.266)\tLoss 1.5243 (1.6024)\tPrec@1 66.406 (65.827)\tPrec@5 84.375 (83.367)\n",
      "Epoch: [0][52040/77344]\tTime 2.752 (4.356)\tData 0.012 (0.960)\tLoss 1.5979 (1.5989)\tPrec@1 62.500 (65.796)\tPrec@5 82.812 (83.575)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "train_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                      images_csv=\"train_images.csv\",\n",
    "                                      bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                      with_label=True,\n",
    "                                      resize=160)\n",
    "val_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                    images_csv=\"val_images.csv\",\n",
    "                                    bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                    with_label=True,\n",
    "                                    resize=160)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['val_batch_size'], shuffle=True, num_workers=6)\n",
    "\n",
    "# define model\n",
    "print(\"=> using pre-trained model '{}'\".format(config['arch']))\n",
    "model = models.__dict__[config['arch']](pretrained=config['pretrained'])\n",
    "\n",
    "classifier_layer = [\n",
    "    torch.nn.Linear(in_features=12800, out_features=5270)\n",
    "]\n",
    "\n",
    "classifier = torch.nn.Sequential(*classifier_layer)\n",
    "\n",
    "model = assemble_model_with_classifier(model, -1, classifier)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "print(model)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# get trainer\n",
    "Trainer = get_trainer(train_dataloader, val_dataloader, model, criterion, config)\n",
    "\n",
    "# Run!\n",
    "Trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
