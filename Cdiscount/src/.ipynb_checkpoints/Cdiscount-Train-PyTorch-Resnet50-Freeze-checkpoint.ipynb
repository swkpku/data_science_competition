{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model, assemble_model_with_classifier\n",
    "from model.utils import freeze_layers\n",
    "from trainer.trainer import get_trainer\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# redirect print to file\n",
    "# import sys\n",
    "# sys.stdout = open(\"PyTorch-resnet34-log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'train_batch_size': 256, 'val_batch_size': 256,\n",
    "    'arch': 'resnet50', 'pretrained': True,\n",
    "    'optimizer': 'Adam', 'learning_rate': 1e-3, 'decay_lr_freq': 4e4, 'weight_decay': 1e-5,\n",
    "    'resume': None,\n",
    "    'start_epoch': 0, 'epochs': 10,\n",
    "    'print_freq': 10, 'validate_freq': 1e4, 'save_freq': 1e4,\n",
    "    'best_val_prec1': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n",
      "=> using pre-trained model 'resnet50'\n",
      "0 freezing Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "1 freezing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "2 freezing ReLU (inplace)\n",
      "3 freezing MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "4 freezing Sequential (\n",
      "  (0): Bottleneck (\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (downsample): Sequential (\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck (\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (2): Bottleneck (\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      ")\n",
      "5 freezing Sequential (\n",
      "  (0): Bottleneck (\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (downsample): Sequential (\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck (\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (2): Bottleneck (\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (3): Bottleneck (\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      ")\n",
      "6 freezing Sequential (\n",
      "  (0): Bottleneck (\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (downsample): Sequential (\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (2): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (3): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (4): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (5): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      ")\n",
      "DataParallel (\n",
      "  (module): AssembledModel (\n",
      "    (model): Sequential (\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): ReLU (inplace)\n",
      "      (3): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "      (4): Sequential (\n",
      "        (0): Bottleneck (\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "          (downsample): Sequential (\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck (\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (2): Bottleneck (\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential (\n",
      "        (0): Bottleneck (\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "          (downsample): Sequential (\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck (\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (2): Bottleneck (\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (3): Bottleneck (\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential (\n",
      "        (0): Bottleneck (\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "          (downsample): Sequential (\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (2): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (3): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (4): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (5): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential (\n",
      "        (0): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "          (downsample): Sequential (\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck (\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (2): Bottleneck (\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "      )\n",
      "      (8): AvgPool2d (size=7, stride=7, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (classifier): Sequential (\n",
      "      (0): Linear (2048 -> 5270)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "train_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                      images_csv=\"train_images.csv\",\n",
    "                                      bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                      with_label=True,\n",
    "                                      resize=224)\n",
    "val_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                    images_csv=\"val_images.csv\",\n",
    "                                    bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                    with_label=True,\n",
    "                                    resize=224)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['val_batch_size'], shuffle=True, num_workers=6)\n",
    "\n",
    "# define model\n",
    "print(\"=> using pre-trained model '{}'\".format(config['arch']))\n",
    "model = models.__dict__[config['arch']](pretrained=config['pretrained'])\n",
    "\n",
    "# model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "# model.add_module('classifier', torch.nn.Linear(in_features=2048, out_features=5270))\n",
    "# model = torch.nn.DataParallel(model).cuda()\n",
    "# print(model)\n",
    "\n",
    "freeze_layers(model, 7)\n",
    "\n",
    "classifier_layer = [\n",
    "    torch.nn.Linear(in_features=2048, out_features=5270)\n",
    "]\n",
    "\n",
    "# classifier_layer = [\n",
    "#     torch.nn.Linear(in_features=2048, out_features=5270),\n",
    "# ]\n",
    "\n",
    "classifier = torch.nn.Sequential(*classifier_layer)\n",
    "\n",
    "model = assemble_model_with_classifier(model, -1, classifier)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Epoch: [0][0/38680]\tTime 29.972 (29.972)\tData 8.536 (8.536)\tLoss 8.6606 (8.6606)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][10/38680]\tTime 2.188 (4.681)\tData 0.011 (0.791)\tLoss 6.7631 (7.4294)\tPrec@1 8.984 (7.102)\tPrec@5 16.797 (13.352)\n",
      "Epoch: [0][20/38680]\tTime 2.175 (3.493)\tData 0.015 (0.421)\tLoss 6.5708 (7.1233)\tPrec@1 10.547 (8.222)\tPrec@5 25.000 (16.443)\n",
      "Epoch: [0][30/38680]\tTime 2.176 (3.074)\tData 0.025 (0.290)\tLoss 6.1700 (6.9023)\tPrec@1 12.500 (8.858)\tPrec@5 25.781 (18.372)\n",
      "Epoch: [0][40/38680]\tTime 2.198 (2.860)\tData 0.019 (0.223)\tLoss 6.0771 (6.7163)\tPrec@1 11.719 (9.546)\tPrec@5 28.906 (20.303)\n",
      "Epoch: [0][50/38680]\tTime 2.197 (2.732)\tData 0.017 (0.183)\tLoss 5.7032 (6.5504)\tPrec@1 17.188 (10.669)\tPrec@5 32.812 (22.258)\n",
      "Epoch: [0][60/38680]\tTime 2.201 (2.645)\tData 0.012 (0.155)\tLoss 5.6009 (6.4116)\tPrec@1 17.188 (11.482)\tPrec@5 29.688 (23.662)\n",
      "Epoch: [0][70/38680]\tTime 2.201 (2.583)\tData 0.016 (0.136)\tLoss 5.5572 (6.3053)\tPrec@1 16.797 (12.230)\tPrec@5 33.203 (24.780)\n",
      "Epoch: [0][80/38680]\tTime 2.214 (2.537)\tData 0.012 (0.122)\tLoss 5.1601 (6.2025)\tPrec@1 20.312 (12.968)\tPrec@5 36.328 (26.027)\n",
      "Epoch: [0][90/38680]\tTime 2.216 (2.502)\tData 0.014 (0.110)\tLoss 5.4814 (6.1054)\tPrec@1 15.625 (13.543)\tPrec@5 35.938 (27.116)\n",
      "Epoch: [0][100/38680]\tTime 2.204 (2.473)\tData 0.016 (0.101)\tLoss 5.4779 (6.0166)\tPrec@1 16.406 (14.217)\tPrec@5 33.984 (28.137)\n",
      "Epoch: [0][110/38680]\tTime 2.201 (2.449)\tData 0.012 (0.093)\tLoss 5.2533 (5.9261)\tPrec@1 21.875 (14.942)\tPrec@5 35.938 (29.096)\n",
      "Epoch: [0][120/38680]\tTime 2.222 (2.430)\tData 0.012 (0.087)\tLoss 4.9994 (5.8493)\tPrec@1 22.266 (15.602)\tPrec@5 39.844 (29.978)\n",
      "Epoch: [0][130/38680]\tTime 2.221 (2.414)\tData 0.015 (0.082)\tLoss 5.0016 (5.7884)\tPrec@1 21.484 (16.060)\tPrec@5 37.891 (30.636)\n",
      "Epoch: [0][140/38680]\tTime 2.215 (2.401)\tData 0.015 (0.077)\tLoss 4.8462 (5.7302)\tPrec@1 16.797 (16.445)\tPrec@5 37.500 (31.175)\n",
      "Epoch: [0][150/38680]\tTime 2.224 (2.389)\tData 0.020 (0.073)\tLoss 4.9092 (5.6820)\tPrec@1 23.047 (16.761)\tPrec@5 41.797 (31.742)\n",
      "Epoch: [0][160/38680]\tTime 2.237 (2.378)\tData 0.016 (0.070)\tLoss 4.8767 (5.6316)\tPrec@1 21.875 (17.137)\tPrec@5 42.188 (32.310)\n",
      "Epoch: [0][170/38680]\tTime 2.214 (2.369)\tData 0.012 (0.066)\tLoss 4.9980 (5.5779)\tPrec@1 22.656 (17.583)\tPrec@5 35.938 (32.876)\n",
      "Epoch: [0][180/38680]\tTime 2.237 (2.362)\tData 0.019 (0.063)\tLoss 4.8276 (5.5270)\tPrec@1 24.609 (18.018)\tPrec@5 41.406 (33.445)\n",
      "Epoch: [0][190/38680]\tTime 2.238 (2.355)\tData 0.012 (0.061)\tLoss 4.9592 (5.4836)\tPrec@1 23.047 (18.386)\tPrec@5 37.891 (33.939)\n",
      "Epoch: [0][200/38680]\tTime 2.231 (2.350)\tData 0.019 (0.059)\tLoss 4.6026 (5.4416)\tPrec@1 26.953 (18.769)\tPrec@5 42.578 (34.433)\n",
      "Epoch: [0][210/38680]\tTime 2.229 (2.344)\tData 0.016 (0.057)\tLoss 4.7349 (5.3991)\tPrec@1 24.609 (19.170)\tPrec@5 42.188 (34.934)\n",
      "Epoch: [0][220/38680]\tTime 2.224 (2.339)\tData 0.012 (0.055)\tLoss 4.6772 (5.3626)\tPrec@1 20.312 (19.503)\tPrec@5 41.406 (35.333)\n",
      "Epoch: [0][230/38680]\tTime 2.248 (2.335)\tData 0.020 (0.053)\tLoss 4.4265 (5.3247)\tPrec@1 30.859 (19.817)\tPrec@5 45.703 (35.723)\n",
      "Epoch: [0][240/38680]\tTime 2.234 (2.331)\tData 0.019 (0.052)\tLoss 4.7800 (5.2911)\tPrec@1 23.828 (20.092)\tPrec@5 44.141 (36.093)\n",
      "Epoch: [0][250/38680]\tTime 2.256 (2.327)\tData 0.014 (0.050)\tLoss 4.0362 (5.2578)\tPrec@1 29.688 (20.386)\tPrec@5 50.391 (36.464)\n",
      "Epoch: [0][260/38680]\tTime 2.249 (2.324)\tData 0.017 (0.049)\tLoss 4.5856 (5.2273)\tPrec@1 26.172 (20.649)\tPrec@5 42.969 (36.794)\n",
      "Epoch: [0][270/38680]\tTime 2.254 (2.321)\tData 0.012 (0.048)\tLoss 4.5596 (5.1956)\tPrec@1 25.000 (20.891)\tPrec@5 39.062 (37.124)\n",
      "Epoch: [0][280/38680]\tTime 2.237 (2.318)\tData 0.013 (0.046)\tLoss 4.0600 (5.1656)\tPrec@1 31.250 (21.187)\tPrec@5 50.391 (37.487)\n",
      "Epoch: [0][290/38680]\tTime 2.229 (2.315)\tData 0.024 (0.045)\tLoss 4.1687 (5.1341)\tPrec@1 31.641 (21.479)\tPrec@5 51.172 (37.846)\n",
      "Epoch: [0][300/38680]\tTime 2.251 (2.313)\tData 0.012 (0.045)\tLoss 4.2981 (5.1050)\tPrec@1 31.250 (21.732)\tPrec@5 48.047 (38.162)\n",
      "Epoch: [0][310/38680]\tTime 2.233 (2.310)\tData 0.016 (0.044)\tLoss 4.1530 (5.0771)\tPrec@1 29.297 (21.949)\tPrec@5 46.875 (38.455)\n",
      "Epoch: [0][320/38680]\tTime 2.243 (2.308)\tData 0.012 (0.043)\tLoss 4.4258 (5.0533)\tPrec@1 25.391 (22.159)\tPrec@5 46.484 (38.736)\n",
      "Epoch: [0][330/38680]\tTime 2.216 (2.306)\tData 0.017 (0.042)\tLoss 3.8350 (5.0228)\tPrec@1 37.891 (22.460)\tPrec@5 55.859 (39.132)\n",
      "Epoch: [0][340/38680]\tTime 2.246 (2.304)\tData 0.013 (0.041)\tLoss 3.8272 (4.9966)\tPrec@1 32.031 (22.673)\tPrec@5 57.031 (39.447)\n",
      "Epoch: [0][350/38680]\tTime 2.233 (2.302)\tData 0.013 (0.040)\tLoss 3.9864 (4.9746)\tPrec@1 33.984 (22.870)\tPrec@5 51.562 (39.711)\n",
      "Epoch: [0][360/38680]\tTime 2.233 (2.300)\tData 0.016 (0.040)\tLoss 3.9919 (4.9506)\tPrec@1 31.641 (23.087)\tPrec@5 50.781 (39.987)\n",
      "Epoch: [0][370/38680]\tTime 2.242 (2.299)\tData 0.019 (0.039)\tLoss 3.7696 (4.9266)\tPrec@1 35.156 (23.326)\tPrec@5 52.344 (40.262)\n",
      "Epoch: [0][380/38680]\tTime 2.229 (2.297)\tData 0.016 (0.039)\tLoss 4.4218 (4.9054)\tPrec@1 26.562 (23.533)\tPrec@5 45.312 (40.508)\n",
      "Epoch: [0][390/38680]\tTime 2.257 (2.296)\tData 0.015 (0.038)\tLoss 4.2391 (4.8822)\tPrec@1 28.516 (23.760)\tPrec@5 46.094 (40.783)\n",
      "Epoch: [0][400/38680]\tTime 2.239 (2.295)\tData 0.016 (0.037)\tLoss 4.2147 (4.8631)\tPrec@1 34.766 (23.953)\tPrec@5 48.828 (41.015)\n",
      "Epoch: [0][410/38680]\tTime 2.231 (2.293)\tData 0.018 (0.037)\tLoss 3.9646 (4.8441)\tPrec@1 28.516 (24.125)\tPrec@5 50.391 (41.223)\n",
      "Epoch: [0][420/38680]\tTime 2.220 (2.292)\tData 0.019 (0.036)\tLoss 3.7687 (4.8249)\tPrec@1 35.547 (24.309)\tPrec@5 51.172 (41.448)\n",
      "Epoch: [0][430/38680]\tTime 2.235 (2.291)\tData 0.015 (0.036)\tLoss 3.9143 (4.8064)\tPrec@1 32.422 (24.505)\tPrec@5 51.172 (41.656)\n",
      "Epoch: [0][440/38680]\tTime 2.222 (2.290)\tData 0.016 (0.036)\tLoss 3.8417 (4.7878)\tPrec@1 35.938 (24.678)\tPrec@5 56.250 (41.875)\n",
      "Epoch: [0][450/38680]\tTime 2.245 (2.288)\tData 0.013 (0.035)\tLoss 4.1416 (4.7689)\tPrec@1 29.688 (24.853)\tPrec@5 48.438 (42.090)\n",
      "Epoch: [0][460/38680]\tTime 2.227 (2.287)\tData 0.036 (0.035)\tLoss 4.2209 (4.7509)\tPrec@1 27.734 (25.031)\tPrec@5 48.438 (42.298)\n",
      "Epoch: [0][470/38680]\tTime 2.234 (2.286)\tData 0.013 (0.034)\tLoss 4.0217 (4.7334)\tPrec@1 29.297 (25.175)\tPrec@5 53.125 (42.503)\n",
      "Epoch: [0][480/38680]\tTime 2.238 (2.285)\tData 0.019 (0.034)\tLoss 3.8134 (4.7149)\tPrec@1 29.688 (25.347)\tPrec@5 50.781 (42.704)\n",
      "Epoch: [0][490/38680]\tTime 2.251 (2.284)\tData 0.038 (0.034)\tLoss 3.7081 (4.6984)\tPrec@1 37.109 (25.520)\tPrec@5 53.125 (42.900)\n",
      "Epoch: [0][500/38680]\tTime 2.245 (2.284)\tData 0.015 (0.033)\tLoss 3.9708 (4.6831)\tPrec@1 37.109 (25.662)\tPrec@5 53.516 (43.069)\n",
      "Epoch: [0][510/38680]\tTime 2.232 (2.283)\tData 0.014 (0.033)\tLoss 3.8347 (4.6689)\tPrec@1 35.938 (25.789)\tPrec@5 55.469 (43.245)\n",
      "Epoch: [0][520/38680]\tTime 2.231 (2.282)\tData 0.017 (0.033)\tLoss 3.9379 (4.6519)\tPrec@1 32.812 (25.968)\tPrec@5 51.172 (43.445)\n",
      "Epoch: [0][530/38680]\tTime 2.247 (2.281)\tData 0.013 (0.033)\tLoss 3.8112 (4.6357)\tPrec@1 35.547 (26.137)\tPrec@5 54.688 (43.640)\n"
     ]
    }
   ],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# get trainer\n",
    "Trainer = get_trainer(train_dataloader, val_dataloader, model, criterion, config)\n",
    "\n",
    "# Run!\n",
    "Trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
