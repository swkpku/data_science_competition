{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "from io import BytesIO\n",
    "import bson\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CdiscountDataset(Dataset):\n",
    "    \"\"\"Cdiscount dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, offsets_csv, images_csv, bson_file_path, with_label, transform=None):\n",
    "        self.offsets_df = pd.read_csv(offsets_csv, index_col=0)\n",
    "        self.images_df = pd.read_csv(images_csv, index_col=0)\n",
    "        self.bson_file = open(bson_file_path, \"rb\")\n",
    "        self.with_label = with_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_row = self.images_df.iloc[idx]\n",
    "        product_id = image_row[\"product_id\"]\n",
    "        offset_row = self.offsets_df.loc[product_id]\n",
    "\n",
    "        # Read this product's data from the BSON file.\n",
    "        self.bson_file.seek(offset_row[\"offset\"])\n",
    "        item_data = self.bson_file.read(offset_row[\"length\"])\n",
    "\n",
    "        # Grab the image from the product.\n",
    "        item = bson.BSON.decode(item_data)\n",
    "        img_idx = image_row[\"img_idx\"]\n",
    "        bson_img = item[\"imgs\"][img_idx][\"picture\"]\n",
    "        img = io.imread(BytesIO(bson_img))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        label = torch.FloatTensor(1)        \n",
    "        if self.with_label:\n",
    "            label = torch.FloatTensor([image_row[\"category_idx\"].item()])\n",
    "\n",
    "        sample = {'img': img, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img = transform.resize(sample, (self.output_size, self.output_size))\n",
    "        return img\n",
    "    \n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        sample = sample.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(sample)\n",
    "\n",
    "# train_dataset = CdiscountDataset(\n",
    "#     offsets_csv=\"train_offsets.csv\",\n",
    "#     images_csv=\"dev_train_images.csv\",\n",
    "#     bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "#     with_label=True,\n",
    "#     transform=transforms.Compose([\n",
    "#         Rescale(128),\n",
    "#         ToTensor()\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "val_dataset = CdiscountDataset(\n",
    "    offsets_csv=\"train_offsets.csv\",\n",
    "    images_csv=\"dev_val_images.csv\",\n",
    "    bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "    with_label=True,\n",
    "    transform=transforms.Compose([\n",
    "        Rescale(256),\n",
    "        ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(val_dataset)):\n",
    "#     sample = val_dataset[i]\n",
    "#     img, label = sample['img'], sample['label']\n",
    "#     print(label)\n",
    "#     if i == 30:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=512, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f40a6de1dd8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 241, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 237, in _shutdown_workers\n",
      "    self.index_queue.put(None)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.042221000000012054\n",
      "1\n",
      "0.07671400000000972\n",
      "2\n",
      "0.07833500000000981\n",
      "3\n",
      "0.06738400000000411\n",
      "4\n",
      "0.06701400000000035\n",
      "5\n",
      "0.06327400000000694\n",
      "6\n",
      "0.06129500000000121\n",
      "7\n",
      "0.06340099999999893\n",
      "8\n",
      "0.0669019999999989\n",
      "9\n",
      "0.07105000000001382\n",
      "10\n",
      "0.06867000000002577\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start = time.clock()\n",
    "for i_batch, sample_batched in enumerate(val_dataloader):\n",
    "    print(i_batch)\n",
    "    print(time.clock() - time_start)\n",
    "    time_start = time.clock()\n",
    "    if (i_batch == 10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
