{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model\n",
    "from predictor.predictor import get_predictor\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'test_batch_size': 1000,\n",
    "    'arch': 'resnet34',\n",
    "    'checkpoint': 'resnet34_checkpoint_epoch_0_iter_3000.pth.tar',\n",
    "    'print_freq': 10,\n",
    "    'pred_filename': \"Resnet34-Epoch_0-iter-3000.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n",
      "=> using pre-trained model 'resnet34'\n",
      "=> loading checkpoint 'resnet34_checkpoint_epoch_0_iter_3000.pth.tar'\n",
      "=> loaded checkpoint:\n",
      "Epoch: [0][3000]\tLoss 3.0118 (3.5749)\tPrec@1 44.922 (40.549)\tPrec@5 64.844 (57.848)\n",
      "start prediction\n",
      "Iter: [0]\tTime 8.950\tData 8.259\t\n",
      "Iter: [1]\tTime 0.682\tData 0.008\t\n",
      "Iter: [2]\tTime 0.547\tData 0.016\t\n",
      "Iter: [3]\tTime 0.593\tData 0.005\t\n",
      "Iter: [4]\tTime 0.568\tData 0.004\t\n",
      "Iter: [5]\tTime 0.705\tData 0.002\t\n",
      "Iter: [6]\tTime 4.058\tData 3.429\t\n",
      "Iter: [7]\tTime 0.534\tData 0.010\t\n",
      "Iter: [8]\tTime 0.578\tData 0.008\t\n",
      "Iter: [9]\tTime 0.531\tData 0.009\t\n",
      "Iter: [10]\tTime 0.624\tData 0.017\t\n",
      "Iter: [11]\tTime 0.629\tData 0.019\t\n",
      "Iter: [12]\tTime 4.545\tData 4.011\t\n",
      "Iter: [13]\tTime 0.555\tData 0.006\t\n",
      "Iter: [14]\tTime 0.708\tData 0.016\t\n",
      "Iter: [15]\tTime 0.749\tData 0.007\t\n",
      "Iter: [16]\tTime 0.735\tData 0.008\t\n",
      "Iter: [17]\tTime 0.759\tData 0.017\t\n",
      "Iter: [18]\tTime 4.349\tData 3.714\t\n",
      "Iter: [19]\tTime 0.816\tData 0.022\t\n",
      "Iter: [20]\tTime 0.713\tData 0.005\t\n",
      "Iter: [21]\tTime 0.678\tData 0.011\t\n",
      "Iter: [22]\tTime 0.735\tData 0.006\t\n",
      "Iter: [23]\tTime 0.708\tData 0.013\t\n",
      "Iter: [24]\tTime 4.146\tData 3.370\t\n",
      "Iter: [25]\tTime 0.701\tData 0.006\t\n",
      "Iter: [26]\tTime 0.764\tData 0.010\t\n",
      "Iter: [27]\tTime 0.697\tData 0.007\t\n",
      "Iter: [28]\tTime 0.673\tData 0.016\t\n",
      "Iter: [29]\tTime 0.773\tData 0.013\t\n",
      "Iter: [30]\tTime 4.067\tData 3.386\t\n",
      "Iter: [31]\tTime 0.741\tData 0.033\t\n",
      "Iter: [32]\tTime 0.903\tData 0.029\t\n",
      "Iter: [33]\tTime 0.770\tData 0.007\t\n",
      "Iter: [34]\tTime 0.820\tData 0.031\t\n",
      "Iter: [35]\tTime 0.869\tData 0.011\t\n",
      "Iter: [36]\tTime 3.685\tData 3.249\t\n",
      "Iter: [37]\tTime 0.842\tData 0.001\t\n",
      "Iter: [38]\tTime 0.768\tData 0.003\t\n",
      "Iter: [39]\tTime 0.687\tData 0.009\t\n",
      "Iter: [40]\tTime 0.758\tData 0.008\t\n",
      "Iter: [41]\tTime 0.791\tData 0.009\t\n",
      "Iter: [42]\tTime 3.500\tData 2.728\t\n",
      "Iter: [43]\tTime 0.897\tData 0.091\t\n",
      "Iter: [44]\tTime 0.751\tData 0.007\t\n",
      "Iter: [45]\tTime 0.741\tData 0.013\t\n",
      "Iter: [46]\tTime 0.886\tData 0.009\t\n",
      "Iter: [47]\tTime 0.606\tData 0.004\t\n",
      "Iter: [48]\tTime 3.837\tData 3.216\t\n",
      "Iter: [49]\tTime 0.684\tData 0.010\t\n",
      "Iter: [50]\tTime 0.737\tData 0.006\t\n",
      "Iter: [51]\tTime 0.814\tData 0.007\t\n",
      "Iter: [52]\tTime 0.689\tData 0.007\t\n",
      "Iter: [53]\tTime 0.868\tData 0.012\t\n",
      "Iter: [54]\tTime 4.592\tData 3.886\t\n",
      "Iter: [55]\tTime 0.546\tData 0.027\t\n",
      "Iter: [56]\tTime 0.579\tData 0.005\t\n",
      "Iter: [57]\tTime 0.728\tData 0.026\t\n",
      "Iter: [58]\tTime 0.696\tData 0.027\t\n",
      "Iter: [59]\tTime 0.935\tData 0.042\t\n",
      "Iter: [60]\tTime 4.228\tData 3.578\t\n",
      "Iter: [61]\tTime 0.689\tData 0.019\t\n",
      "Iter: [62]\tTime 0.690\tData 0.028\t\n",
      "Iter: [63]\tTime 0.712\tData 0.020\t\n",
      "Iter: [64]\tTime 0.694\tData 0.011\t\n",
      "Iter: [65]\tTime 0.682\tData 0.018\t\n",
      "Iter: [66]\tTime 4.426\tData 3.698\t\n",
      "Iter: [67]\tTime 0.797\tData 0.002\t\n",
      "Iter: [68]\tTime 0.712\tData 0.014\t\n",
      "Iter: [69]\tTime 0.752\tData 0.017\t\n",
      "Iter: [70]\tTime 0.680\tData 0.005\t\n",
      "Iter: [71]\tTime 0.673\tData 0.009\t\n",
      "Iter: [72]\tTime 4.006\tData 3.444\t\n",
      "Iter: [73]\tTime 0.801\tData 0.056\t\n",
      "Iter: [74]\tTime 0.807\tData 0.013\t\n",
      "Iter: [75]\tTime 0.832\tData 0.006\t\n",
      "Iter: [76]\tTime 0.847\tData 0.025\t\n",
      "Iter: [77]\tTime 0.845\tData 0.010\t\n",
      "Iter: [78]\tTime 3.843\tData 3.213\t\n",
      "Iter: [79]\tTime 0.755\tData 0.019\t\n",
      "Iter: [80]\tTime 0.642\tData 0.002\t\n",
      "Iter: [81]\tTime 0.820\tData 0.012\t\n",
      "Iter: [82]\tTime 0.854\tData 0.003\t\n",
      "Iter: [83]\tTime 0.923\tData 0.009\t\n",
      "Iter: [84]\tTime 3.793\tData 3.238\t\n",
      "Iter: [85]\tTime 0.637\tData 0.004\t\n",
      "Iter: [86]\tTime 0.735\tData 0.017\t\n",
      "Iter: [87]\tTime 0.692\tData 0.026\t\n",
      "Iter: [88]\tTime 0.696\tData 0.014\t\n",
      "Iter: [89]\tTime 0.880\tData 0.006\t\n",
      "Iter: [90]\tTime 4.302\tData 3.643\t\n",
      "Iter: [91]\tTime 0.633\tData 0.014\t\n",
      "Iter: [92]\tTime 0.714\tData 0.017\t\n",
      "Iter: [93]\tTime 0.699\tData 0.011\t\n",
      "Iter: [94]\tTime 0.738\tData 0.007\t\n",
      "Iter: [95]\tTime 0.572\tData 0.009\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Process Process-2:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-3:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 53, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "Process Process-4:\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 15, in __call__\n",
      "    img = transform.resize(sample, (self.output_size, self.output_size))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 135, in resize\n",
      "    preserve_range=preserve_range)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 775, in warp\n",
      "    order=order, mode=mode, cval=cval))\n",
      "  File \"skimage/transform/_warps_cy.pyx\", line 131, in skimage.transform._warps_cy._warp_fast (skimage/transform/_warps_cy.c:2968)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/tensorflow/lib/python3.5/site-packages/numpy/core/numeric.py\", line 463, in asarray\n",
      "    def asarray(a, dtype=None, order=None):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 53, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 15, in __call__\n",
      "    img = transform.resize(sample, (self.output_size, self.output_size))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 135, in resize\n",
      "    preserve_range=preserve_range)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 53, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 775, in warp\n",
      "    order=order, mode=mode, cval=cval))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 53, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"skimage/transform/_warps_cy.pyx\", line 131, in skimage.transform._warps_cy._warp_fast (skimage/transform/_warps_cy.c:2968)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 15, in __call__\n",
      "    img = transform.resize(sample, (self.output_size, self.output_size))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 131, in resize\n",
      "    tform.estimate(src_corners, dst_corners)\n",
      "  File \"/home/weiso/tensorflow/lib/python3.5/site-packages/numpy/core/numeric.py\", line 463, in asarray\n",
      "    def asarray(a, dtype=None, order=None):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_geometric.py\", line 688, in estimate\n",
      "    H = np.dot(np.linalg.inv(dst_matrix), np.dot(H, src_matrix))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weiso/tensorflow/lib/python3.5/site-packages/numpy/linalg/linalg.py\", line 513, in inv\n",
      "    ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 15, in __call__\n",
      "    img = transform.resize(sample, (self.output_size, self.output_size))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 53, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 15, in __call__\n",
      "    img = transform.resize(sample, (self.output_size, self.output_size))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 131, in resize\n",
      "    tform.estimate(src_corners, dst_corners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 131, in resize\n",
      "    tform.estimate(src_corners, dst_corners)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_geometric.py\", line 688, in estimate\n",
      "    H = np.dot(np.linalg.inv(dst_matrix), np.dot(H, src_matrix))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_geometric.py\", line 688, in estimate\n",
      "    H = np.dot(np.linalg.inv(dst_matrix), np.dot(H, src_matrix))\n",
      "  File \"/home/weiso/tensorflow/lib/python3.5/site-packages/numpy/linalg/linalg.py\", line 513, in inv\n",
      "    ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj)\n",
      "  File \"/home/weiso/tensorflow/lib/python3.5/site-packages/numpy/linalg/linalg.py\", line 513, in inv\n",
      "    ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 53, in __getitem__\n",
      "    img = self.transform(img)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/weiso/kaggle/Cdiscount/src/dataset/dataset.py\", line 15, in __call__\n",
      "    img = transform.resize(sample, (self.output_size, self.output_size))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 135, in resize\n",
      "    preserve_range=preserve_range)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 776, in warp\n",
      "    warped = np.dstack(dims)\n",
      "  File \"/home/weiso/tensorflow/lib/python3.5/site-packages/numpy/lib/shape_base.py\", line 409, in dstack\n",
      "    return _nx.concatenate([atleast_3d(_m) for _m in tup], 2)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-42ffc367c0d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Run!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mPredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kaggle/Cdiscount/src/predictor/predictor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprod_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mdata_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "test_dataset = get_cdiscount_dataset(offsets_csv=\"test_offsets.csv\",\n",
    "                                     images_csv=\"test_images.csv\",\n",
    "                                     bson_file_path=\"/mnt/data/cdiscount/test.bson\",\n",
    "                                     with_label=False,\n",
    "                                     resize=256)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['test_batch_size'], shuffle=False, num_workers=6)\n",
    "\n",
    "# define model\n",
    "print(\"=> using pre-trained model '{}'\".format(config['arch']))\n",
    "model = models.__dict__[config['arch']](pretrained=True)\n",
    "model = assemble_model(model, -1, 512, 5270)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "\n",
    "# load checkpoint\n",
    "if not os.path.isfile(config['checkpoint']):\n",
    "    print(\"=> no checkpoint found at '{}'\".format(config['checkpoint']))\n",
    "    \n",
    "print(\"=> loading checkpoint '{}'\".format(config['checkpoint']))\n",
    "checkpoint = torch.load(config['checkpoint'])\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"=> loaded checkpoint:\")\n",
    "\n",
    "print('Epoch: [{0}][{1}]\\t'\n",
    "      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "       checkpoint['epoch'], checkpoint['iter'], loss=checkpoint['loss'], top1=checkpoint['top1'], top5=checkpoint['top5']))\n",
    "\n",
    "# get trainer\n",
    "Predictor = get_predictor(test_dataloader, model, config)\n",
    "\n",
    "# Run!\n",
    "Predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
