{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import get_cdiscount_dataset\n",
    "from model.model import assemble_model, assemble_model_with_classifier\n",
    "from model.utils import freeze_layers\n",
    "from trainer.trainer import get_trainer\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# redirect print to file\n",
    "# import sys\n",
    "# sys.stdout = open(\"PyTorch-resnet34-log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'train_batch_size': 256, 'val_batch_size': 256,\n",
    "    'arch': 'resnet152', 'pretrained': True,\n",
    "    'optimizer': 'Adam', 'learning_rate': 1e-3, 'decay_lr_freq': 4e4, 'weight_decay': 1e-5,\n",
    "    'resume': None,\n",
    "    'start_epoch': 0, 'epochs': 10,\n",
    "    'print_freq': 10, 'validate_freq': 1e4, 'save_freq': 1e4,\n",
    "    'best_val_prec1': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset...\n",
      "getting data loader...\n",
      "=> using pre-trained model 'resnet50'\n",
      "0 freezing Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "1 freezing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "2 freezing ReLU (inplace)\n",
      "3 freezing MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "4 freezing Sequential (\n",
      "  (0): Bottleneck (\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (downsample): Sequential (\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck (\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (2): Bottleneck (\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      ")\n",
      "5 freezing Sequential (\n",
      "  (0): Bottleneck (\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (downsample): Sequential (\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck (\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (2): Bottleneck (\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (3): Bottleneck (\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      ")\n",
      "6 freezing Sequential (\n",
      "  (0): Bottleneck (\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (downsample): Sequential (\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (2): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (3): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (4): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      "  (5): Bottleneck (\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "  )\n",
      ")\n",
      "DataParallel (\n",
      "  (module): AssembledModel (\n",
      "    (model): Sequential (\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): ReLU (inplace)\n",
      "      (3): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "      (4): Sequential (\n",
      "        (0): Bottleneck (\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "          (downsample): Sequential (\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck (\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (2): Bottleneck (\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential (\n",
      "        (0): Bottleneck (\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "          (downsample): Sequential (\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck (\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (2): Bottleneck (\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (3): Bottleneck (\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential (\n",
      "        (0): Bottleneck (\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "          (downsample): Sequential (\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (2): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (3): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (4): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (5): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential (\n",
      "        (0): Bottleneck (\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "          (downsample): Sequential (\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck (\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "        (2): Bottleneck (\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU (inplace)\n",
      "        )\n",
      "      )\n",
      "      (8): AvgPool2d (size=7, stride=7, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (classifier): Sequential (\n",
      "      (0): Linear (2048 -> 5270)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# get dataset\n",
    "print('getting dataset...')\n",
    "train_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                      images_csv=\"train_images.csv\",\n",
    "                                      bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                      with_label=True,\n",
    "                                      resize=224)\n",
    "val_dataset = get_cdiscount_dataset(offsets_csv=\"train_offsets.csv\",\n",
    "                                    images_csv=\"val_images.csv\",\n",
    "                                    bson_file_path=\"/mnt/data/cdiscount/train.bson\",\n",
    "                                    with_label=True,\n",
    "                                    resize=224)\n",
    "\n",
    "# get data loader\n",
    "print('getting data loader...')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['val_batch_size'], shuffle=True, num_workers=6)\n",
    "\n",
    "# define model\n",
    "print(\"=> using pre-trained model '{}'\".format(config['arch']))\n",
    "model = models.__dict__[config['arch']](pretrained=config['pretrained'])\n",
    "\n",
    "# model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "# model.add_module('classifier', torch.nn.Linear(in_features=2048, out_features=5270))\n",
    "# model = torch.nn.DataParallel(model).cuda()\n",
    "# print(model)\n",
    "\n",
    "freeze_layers(model, 7)\n",
    "\n",
    "classifier_layer = [\n",
    "    torch.nn.Linear(in_features=2048, out_features=5270)\n",
    "]\n",
    "\n",
    "# classifier_layer = [\n",
    "#     torch.nn.Linear(in_features=2048, out_features=5270),\n",
    "# ]\n",
    "\n",
    "classifier = torch.nn.Sequential(*classifier_layer)\n",
    "\n",
    "model = assemble_model_with_classifier(model, -1, classifier)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Epoch: [0][0/38680]\tTime 29.644 (29.644)\tData 8.393 (8.393)\tLoss 8.5846 (8.5846)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][10/38680]\tTime 2.205 (4.676)\tData 0.013 (0.778)\tLoss 6.7859 (7.4837)\tPrec@1 7.812 (5.256)\tPrec@5 20.312 (13.352)\n",
      "Epoch: [0][20/38680]\tTime 2.189 (3.503)\tData 0.021 (0.415)\tLoss 6.4568 (7.1852)\tPrec@1 10.156 (6.492)\tPrec@5 22.656 (15.699)\n",
      "Epoch: [0][30/38680]\tTime 2.213 (3.087)\tData 0.012 (0.286)\tLoss 6.0839 (6.9030)\tPrec@1 11.719 (7.850)\tPrec@5 24.609 (18.196)\n",
      "Epoch: [0][40/38680]\tTime 2.224 (2.873)\tData 0.015 (0.220)\tLoss 6.3960 (6.7499)\tPrec@1 12.891 (9.137)\tPrec@5 22.656 (20.255)\n",
      "Epoch: [0][50/38680]\tTime 2.215 (2.744)\tData 0.015 (0.181)\tLoss 5.7896 (6.5743)\tPrec@1 13.672 (9.995)\tPrec@5 28.906 (22.051)\n",
      "Epoch: [0][60/38680]\tTime 2.214 (2.658)\tData 0.012 (0.154)\tLoss 5.4124 (6.4484)\tPrec@1 14.844 (10.540)\tPrec@5 33.594 (23.239)\n",
      "Epoch: [0][70/38680]\tTime 2.221 (2.597)\tData 0.016 (0.134)\tLoss 5.4261 (6.3200)\tPrec@1 18.359 (11.356)\tPrec@5 35.547 (24.631)\n",
      "Epoch: [0][80/38680]\tTime 2.233 (2.551)\tData 0.011 (0.119)\tLoss 5.2632 (6.2041)\tPrec@1 21.094 (12.240)\tPrec@5 39.453 (25.863)\n",
      "Epoch: [0][90/38680]\tTime 2.232 (2.516)\tData 0.012 (0.108)\tLoss 4.8669 (6.0994)\tPrec@1 22.266 (13.234)\tPrec@5 39.062 (27.000)\n",
      "Epoch: [0][100/38680]\tTime 2.218 (2.488)\tData 0.015 (0.098)\tLoss 5.3271 (6.0118)\tPrec@1 19.141 (13.788)\tPrec@5 39.062 (27.974)\n",
      "Epoch: [0][110/38680]\tTime 2.251 (2.465)\tData 0.014 (0.091)\tLoss 5.0897 (5.9228)\tPrec@1 19.531 (14.488)\tPrec@5 39.453 (28.941)\n",
      "Epoch: [0][120/38680]\tTime 2.248 (2.446)\tData 0.016 (0.085)\tLoss 4.8549 (5.8444)\tPrec@1 22.656 (15.096)\tPrec@5 43.359 (29.865)\n",
      "Epoch: [0][130/38680]\tTime 2.246 (2.430)\tData 0.015 (0.079)\tLoss 5.3495 (5.7846)\tPrec@1 17.578 (15.476)\tPrec@5 33.984 (30.490)\n",
      "Epoch: [0][140/38680]\tTime 2.244 (2.417)\tData 0.015 (0.075)\tLoss 4.7578 (5.7256)\tPrec@1 22.266 (15.933)\tPrec@5 41.406 (31.114)\n",
      "Epoch: [0][150/38680]\tTime 2.232 (2.405)\tData 0.016 (0.071)\tLoss 5.2290 (5.6653)\tPrec@1 19.922 (16.507)\tPrec@5 38.281 (31.819)\n",
      "Epoch: [0][160/38680]\tTime 2.228 (2.394)\tData 0.013 (0.068)\tLoss 4.7863 (5.6146)\tPrec@1 24.609 (16.974)\tPrec@5 42.969 (32.415)\n",
      "Epoch: [0][170/38680]\tTime 2.236 (2.385)\tData 0.015 (0.065)\tLoss 4.3591 (5.5637)\tPrec@1 29.297 (17.384)\tPrec@5 49.609 (32.929)\n",
      "Epoch: [0][180/38680]\tTime 2.262 (2.377)\tData 0.013 (0.062)\tLoss 4.9823 (5.5128)\tPrec@1 22.266 (17.792)\tPrec@5 37.500 (33.542)\n",
      "Epoch: [0][190/38680]\tTime 2.246 (2.370)\tData 0.023 (0.060)\tLoss 4.4921 (5.4654)\tPrec@1 28.125 (18.216)\tPrec@5 46.094 (34.130)\n",
      "Epoch: [0][200/38680]\tTime 2.242 (2.363)\tData 0.016 (0.057)\tLoss 4.6020 (5.4185)\tPrec@1 25.391 (18.630)\tPrec@5 44.922 (34.676)\n",
      "Epoch: [0][210/38680]\tTime 2.232 (2.357)\tData 0.027 (0.056)\tLoss 4.0839 (5.3770)\tPrec@1 26.953 (18.985)\tPrec@5 49.219 (35.154)\n",
      "Epoch: [0][220/38680]\tTime 2.251 (2.352)\tData 0.015 (0.054)\tLoss 4.3600 (5.3347)\tPrec@1 25.000 (19.353)\tPrec@5 41.797 (35.612)\n",
      "Epoch: [0][230/38680]\tTime 2.261 (2.347)\tData 0.012 (0.052)\tLoss 4.4566 (5.2965)\tPrec@1 28.516 (19.685)\tPrec@5 43.359 (36.034)\n",
      "Epoch: [0][240/38680]\tTime 2.251 (2.342)\tData 0.024 (0.051)\tLoss 4.2092 (5.2596)\tPrec@1 27.734 (19.975)\tPrec@5 46.484 (36.412)\n",
      "Epoch: [0][250/38680]\tTime 2.240 (2.338)\tData 0.013 (0.049)\tLoss 4.0168 (5.2227)\tPrec@1 33.594 (20.292)\tPrec@5 48.047 (36.845)\n",
      "Epoch: [0][260/38680]\tTime 2.226 (2.334)\tData 0.017 (0.048)\tLoss 4.4919 (5.1931)\tPrec@1 26.562 (20.580)\tPrec@5 46.875 (37.240)\n",
      "Epoch: [0][270/38680]\tTime 2.223 (2.331)\tData 0.015 (0.047)\tLoss 4.2244 (5.1592)\tPrec@1 29.688 (20.911)\tPrec@5 44.531 (37.611)\n",
      "Epoch: [0][280/38680]\tTime 2.239 (2.327)\tData 0.014 (0.046)\tLoss 4.6385 (5.1329)\tPrec@1 24.219 (21.149)\tPrec@5 41.016 (37.905)\n",
      "Epoch: [0][290/38680]\tTime 2.244 (2.324)\tData 0.015 (0.045)\tLoss 4.4620 (5.1060)\tPrec@1 27.344 (21.394)\tPrec@5 42.969 (38.166)\n",
      "Epoch: [0][300/38680]\tTime 2.218 (2.321)\tData 0.027 (0.044)\tLoss 4.2914 (5.0755)\tPrec@1 28.516 (21.721)\tPrec@5 45.312 (38.530)\n",
      "Epoch: [0][310/38680]\tTime 2.231 (2.318)\tData 0.019 (0.043)\tLoss 4.1710 (5.0477)\tPrec@1 30.469 (21.975)\tPrec@5 47.266 (38.808)\n",
      "Epoch: [0][320/38680]\tTime 2.239 (2.316)\tData 0.020 (0.042)\tLoss 3.7848 (5.0198)\tPrec@1 36.328 (22.251)\tPrec@5 55.859 (39.112)\n",
      "Epoch: [0][330/38680]\tTime 2.237 (2.313)\tData 0.052 (0.041)\tLoss 3.8358 (4.9933)\tPrec@1 37.109 (22.549)\tPrec@5 52.344 (39.395)\n",
      "Epoch: [0][340/38680]\tTime 2.235 (2.311)\tData 0.014 (0.041)\tLoss 4.0427 (4.9691)\tPrec@1 35.156 (22.796)\tPrec@5 51.953 (39.715)\n",
      "Epoch: [0][350/38680]\tTime 2.242 (2.309)\tData 0.018 (0.040)\tLoss 4.4330 (4.9488)\tPrec@1 23.438 (22.951)\tPrec@5 42.188 (39.924)\n",
      "Epoch: [0][360/38680]\tTime 2.230 (2.307)\tData 0.014 (0.039)\tLoss 3.8864 (4.9253)\tPrec@1 35.156 (23.139)\tPrec@5 53.516 (40.173)\n",
      "Epoch: [0][370/38680]\tTime 2.222 (2.305)\tData 0.015 (0.039)\tLoss 4.2968 (4.9032)\tPrec@1 30.469 (23.346)\tPrec@5 46.094 (40.430)\n",
      "Epoch: [0][380/38680]\tTime 2.247 (2.303)\tData 0.018 (0.038)\tLoss 3.9014 (4.8845)\tPrec@1 30.469 (23.495)\tPrec@5 49.609 (40.633)\n",
      "Epoch: [0][390/38680]\tTime 2.238 (2.302)\tData 0.015 (0.038)\tLoss 4.2314 (4.8650)\tPrec@1 30.469 (23.683)\tPrec@5 49.609 (40.882)\n",
      "Epoch: [0][400/38680]\tTime 2.220 (2.300)\tData 0.015 (0.037)\tLoss 4.0203 (4.8440)\tPrec@1 30.078 (23.891)\tPrec@5 51.172 (41.130)\n",
      "Epoch: [0][410/38680]\tTime 2.228 (2.299)\tData 0.021 (0.037)\tLoss 4.2067 (4.8250)\tPrec@1 31.641 (24.045)\tPrec@5 48.438 (41.372)\n",
      "Epoch: [0][420/38680]\tTime 2.247 (2.297)\tData 0.013 (0.036)\tLoss 4.0206 (4.8059)\tPrec@1 31.641 (24.217)\tPrec@5 53.125 (41.580)\n",
      "Epoch: [0][430/38680]\tTime 2.216 (2.296)\tData 0.014 (0.036)\tLoss 3.5357 (4.7850)\tPrec@1 41.016 (24.453)\tPrec@5 55.859 (41.832)\n",
      "Epoch: [0][440/38680]\tTime 2.248 (2.295)\tData 0.015 (0.035)\tLoss 3.5595 (4.7642)\tPrec@1 35.938 (24.659)\tPrec@5 57.422 (42.072)\n",
      "Epoch: [0][450/38680]\tTime 2.252 (2.293)\tData 0.016 (0.035)\tLoss 3.9178 (4.7468)\tPrec@1 32.031 (24.819)\tPrec@5 50.781 (42.273)\n",
      "Epoch: [0][460/38680]\tTime 2.234 (2.292)\tData 0.019 (0.035)\tLoss 3.5983 (4.7285)\tPrec@1 37.891 (25.003)\tPrec@5 53.906 (42.488)\n",
      "Epoch: [0][470/38680]\tTime 2.220 (2.291)\tData 0.016 (0.034)\tLoss 3.8496 (4.7101)\tPrec@1 32.031 (25.203)\tPrec@5 53.516 (42.724)\n",
      "Epoch: [0][480/38680]\tTime 2.224 (2.289)\tData 0.016 (0.034)\tLoss 4.0806 (4.6943)\tPrec@1 28.516 (25.387)\tPrec@5 50.781 (42.921)\n",
      "Epoch: [0][490/38680]\tTime 2.231 (2.288)\tData 0.013 (0.033)\tLoss 4.1043 (4.6777)\tPrec@1 30.469 (25.540)\tPrec@5 51.562 (43.129)\n",
      "Epoch: [0][500/38680]\tTime 2.240 (2.287)\tData 0.016 (0.033)\tLoss 4.0112 (4.6622)\tPrec@1 34.375 (25.696)\tPrec@5 51.953 (43.320)\n",
      "Epoch: [0][510/38680]\tTime 2.253 (2.287)\tData 0.015 (0.033)\tLoss 3.5985 (4.6448)\tPrec@1 39.844 (25.868)\tPrec@5 57.422 (43.544)\n",
      "Epoch: [0][520/38680]\tTime 2.236 (2.286)\tData 0.013 (0.032)\tLoss 3.9079 (4.6280)\tPrec@1 33.594 (26.028)\tPrec@5 51.953 (43.749)\n",
      "Epoch: [0][530/38680]\tTime 2.245 (2.285)\tData 0.014 (0.032)\tLoss 3.8343 (4.6125)\tPrec@1 35.547 (26.184)\tPrec@5 51.172 (43.928)\n",
      "Epoch: [0][540/38680]\tTime 2.242 (2.284)\tData 0.021 (0.032)\tLoss 3.7793 (4.5983)\tPrec@1 34.375 (26.329)\tPrec@5 51.953 (44.097)\n",
      "Epoch: [0][550/38680]\tTime 2.236 (2.283)\tData 0.017 (0.032)\tLoss 3.7958 (4.5842)\tPrec@1 32.422 (26.476)\tPrec@5 55.859 (44.282)\n",
      "Epoch: [0][560/38680]\tTime 2.236 (2.282)\tData 0.019 (0.031)\tLoss 3.9980 (4.5706)\tPrec@1 31.250 (26.595)\tPrec@5 54.297 (44.439)\n",
      "Epoch: [0][570/38680]\tTime 2.236 (2.282)\tData 0.017 (0.031)\tLoss 4.0625 (4.5577)\tPrec@1 32.031 (26.714)\tPrec@5 53.125 (44.587)\n",
      "Epoch: [0][580/38680]\tTime 2.260 (2.281)\tData 0.016 (0.031)\tLoss 3.8204 (4.5452)\tPrec@1 33.203 (26.857)\tPrec@5 56.250 (44.742)\n",
      "Epoch: [0][590/38680]\tTime 2.264 (2.280)\tData 0.013 (0.031)\tLoss 3.6484 (4.5309)\tPrec@1 34.375 (26.992)\tPrec@5 52.344 (44.912)\n",
      "Epoch: [0][600/38680]\tTime 2.235 (2.279)\tData 0.019 (0.030)\tLoss 3.3577 (4.5169)\tPrec@1 41.797 (27.126)\tPrec@5 62.891 (45.067)\n",
      "Epoch: [0][610/38680]\tTime 2.234 (2.279)\tData 0.019 (0.030)\tLoss 3.9025 (4.5035)\tPrec@1 30.859 (27.256)\tPrec@5 52.734 (45.231)\n",
      "Epoch: [0][620/38680]\tTime 2.233 (2.278)\tData 0.015 (0.030)\tLoss 3.6417 (4.4914)\tPrec@1 37.109 (27.375)\tPrec@5 55.469 (45.379)\n",
      "Epoch: [0][630/38680]\tTime 2.222 (2.277)\tData 0.015 (0.030)\tLoss 3.5598 (4.4779)\tPrec@1 36.719 (27.514)\tPrec@5 56.250 (45.533)\n",
      "Epoch: [0][640/38680]\tTime 2.231 (2.276)\tData 0.016 (0.030)\tLoss 3.8168 (4.4655)\tPrec@1 32.812 (27.637)\tPrec@5 50.781 (45.676)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][650/38680]\tTime 2.222 (2.276)\tData 0.014 (0.029)\tLoss 3.4940 (4.4526)\tPrec@1 39.062 (27.775)\tPrec@5 58.594 (45.845)\n",
      "Epoch: [0][660/38680]\tTime 2.220 (2.275)\tData 0.016 (0.029)\tLoss 3.6670 (4.4413)\tPrec@1 38.672 (27.897)\tPrec@5 55.078 (45.980)\n",
      "Epoch: [0][670/38680]\tTime 2.231 (2.275)\tData 0.013 (0.029)\tLoss 3.5576 (4.4294)\tPrec@1 39.453 (28.033)\tPrec@5 56.250 (46.126)\n",
      "Epoch: [0][680/38680]\tTime 2.226 (2.274)\tData 0.018 (0.029)\tLoss 3.6043 (4.4185)\tPrec@1 35.156 (28.141)\tPrec@5 58.203 (46.257)\n",
      "Epoch: [0][690/38680]\tTime 2.246 (2.274)\tData 0.025 (0.029)\tLoss 3.5067 (4.4081)\tPrec@1 37.109 (28.254)\tPrec@5 57.812 (46.388)\n",
      "Epoch: [0][700/38680]\tTime 2.233 (2.273)\tData 0.016 (0.029)\tLoss 3.5294 (4.3961)\tPrec@1 36.719 (28.381)\tPrec@5 54.297 (46.518)\n",
      "Epoch: [0][710/38680]\tTime 2.228 (2.273)\tData 0.022 (0.028)\tLoss 3.7241 (4.3848)\tPrec@1 33.203 (28.493)\tPrec@5 54.688 (46.646)\n",
      "Epoch: [0][720/38680]\tTime 2.252 (2.272)\tData 0.015 (0.028)\tLoss 3.2291 (4.3729)\tPrec@1 39.453 (28.617)\tPrec@5 58.203 (46.799)\n",
      "Epoch: [0][730/38680]\tTime 2.233 (2.272)\tData 0.026 (0.028)\tLoss 3.5532 (4.3631)\tPrec@1 36.328 (28.705)\tPrec@5 55.859 (46.916)\n",
      "Epoch: [0][740/38680]\tTime 2.237 (2.271)\tData 0.016 (0.028)\tLoss 3.8561 (4.3526)\tPrec@1 33.984 (28.811)\tPrec@5 52.344 (47.042)\n",
      "Epoch: [0][750/38680]\tTime 2.224 (2.271)\tData 0.017 (0.028)\tLoss 3.3189 (4.3416)\tPrec@1 41.406 (28.933)\tPrec@5 61.328 (47.186)\n",
      "Epoch: [0][760/38680]\tTime 2.228 (2.270)\tData 0.018 (0.028)\tLoss 3.6622 (4.3318)\tPrec@1 36.328 (29.032)\tPrec@5 54.688 (47.304)\n",
      "Epoch: [0][770/38680]\tTime 2.251 (2.270)\tData 0.032 (0.028)\tLoss 3.7289 (4.3220)\tPrec@1 34.766 (29.121)\tPrec@5 53.516 (47.425)\n",
      "Epoch: [0][780/38680]\tTime 2.241 (2.269)\tData 0.017 (0.027)\tLoss 3.6468 (4.3115)\tPrec@1 36.328 (29.252)\tPrec@5 55.078 (47.564)\n",
      "Epoch: [0][790/38680]\tTime 2.225 (2.269)\tData 0.015 (0.027)\tLoss 3.6719 (4.3023)\tPrec@1 37.500 (29.363)\tPrec@5 54.297 (47.685)\n",
      "Epoch: [0][800/38680]\tTime 2.221 (2.269)\tData 0.015 (0.027)\tLoss 3.5987 (4.2935)\tPrec@1 38.281 (29.466)\tPrec@5 55.078 (47.786)\n",
      "Epoch: [0][810/38680]\tTime 2.236 (2.268)\tData 0.014 (0.027)\tLoss 3.5726 (4.2832)\tPrec@1 36.719 (29.588)\tPrec@5 53.125 (47.903)\n",
      "Epoch: [0][820/38680]\tTime 2.241 (2.268)\tData 0.030 (0.027)\tLoss 3.5765 (4.2740)\tPrec@1 38.281 (29.695)\tPrec@5 56.250 (48.010)\n",
      "Epoch: [0][830/38680]\tTime 2.247 (2.267)\tData 0.015 (0.027)\tLoss 3.5919 (4.2655)\tPrec@1 38.281 (29.771)\tPrec@5 57.812 (48.122)\n",
      "Epoch: [0][840/38680]\tTime 2.239 (2.267)\tData 0.017 (0.027)\tLoss 3.4692 (4.2564)\tPrec@1 38.281 (29.868)\tPrec@5 58.203 (48.233)\n",
      "Epoch: [0][850/38680]\tTime 2.236 (2.267)\tData 0.017 (0.027)\tLoss 3.9406 (4.2479)\tPrec@1 35.938 (29.969)\tPrec@5 53.906 (48.347)\n",
      "Epoch: [0][860/38680]\tTime 2.223 (2.266)\tData 0.040 (0.027)\tLoss 3.4386 (4.2385)\tPrec@1 39.453 (30.076)\tPrec@5 57.812 (48.457)\n",
      "Epoch: [0][870/38680]\tTime 2.221 (2.266)\tData 0.018 (0.027)\tLoss 3.6057 (4.2303)\tPrec@1 40.625 (30.171)\tPrec@5 58.984 (48.558)\n",
      "Epoch: [0][880/38680]\tTime 2.256 (2.266)\tData 0.015 (0.026)\tLoss 3.6417 (4.2220)\tPrec@1 34.766 (30.270)\tPrec@5 57.422 (48.676)\n",
      "Epoch: [0][890/38680]\tTime 2.237 (2.266)\tData 0.018 (0.026)\tLoss 3.6659 (4.2149)\tPrec@1 37.500 (30.357)\tPrec@5 59.375 (48.770)\n",
      "Epoch: [0][900/38680]\tTime 2.225 (2.265)\tData 0.016 (0.026)\tLoss 3.3521 (4.2067)\tPrec@1 39.062 (30.447)\tPrec@5 59.766 (48.873)\n",
      "Epoch: [0][910/38680]\tTime 2.241 (2.265)\tData 0.021 (0.026)\tLoss 3.4425 (4.1993)\tPrec@1 37.109 (30.530)\tPrec@5 58.203 (48.958)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "KeyboardInterrupt\n",
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Process Process-5:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9852eb190a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data_science_competition/Cdiscount/src/trainer/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data_science_competition/Cdiscount/src/trainer/trainer.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, epoch, start_iter)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mprec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mtop5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/weiso/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weiso/data_science_competition/Cdiscount/src/dataset/dataset.py\", line 53, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weiso/data_science_competition/Cdiscount/src/dataset/dataset.py\", line 15, in __call__\n",
      "    img = transform.resize(sample, (self.output_size, self.output_size))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 135, in resize\n",
      "    preserve_range=preserve_range)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 722, in warp\n",
      "    image = _convert_warp_input(image, preserve_range)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 535, in _convert_warp_input\n",
      "    image = img_as_float(image)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py\", line 336, in img_as_float\n",
      "    return convert(image, np.float64, force_copy)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py\", line 274, in convert\n",
      "    image /= imax_in\n"
     ]
    }
   ],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# get trainer\n",
    "Trainer = get_trainer(train_dataloader, val_dataloader, model, criterion, config)\n",
    "\n",
    "# Run!\n",
    "Trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
