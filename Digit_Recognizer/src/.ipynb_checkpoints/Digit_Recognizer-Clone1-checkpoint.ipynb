{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (42000, 784)\n",
      "label shape:  (42000,)\n",
      "test image shape:  (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "data_path = '../data/'\n",
    "\n",
    "filename = data_path + 'train.csv'\n",
    "#data, label = read_data(filename)\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "images = data.as_matrix(columns=[data.columns[1:]])\n",
    "print('image shape: ', images.shape)\n",
    "\n",
    "labels = data.as_matrix(columns=[data.columns[0]])\n",
    "labels = labels.reshape(labels.shape[0])\n",
    "print('label shape: ', labels.shape)\n",
    "\n",
    "test_filename = data_path + 'test.csv'\n",
    "test_data = pd.read_csv(test_filename)\n",
    "test_images = test_data.as_matrix(columns=[test_data.columns[:]])\n",
    "print('test image shape: ', test_images.shape)\n",
    "\n",
    "num_data = images.shape[0]\n",
    "data_dim = images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f634ee1fb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def display_img(dataset, idx):\n",
    "    image = dataset[idx]\n",
    "    image_width = image_height = np.ceil(np.sqrt(data_dim)).astype(np.uint8)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(image_width, image_height), cmap=cm.binary)\n",
    "    plt.show()\n",
    "    \n",
    "display_img(images, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image shape:  (41000, 784)\n",
      "train label shape:  (41000,)\n",
      "val image shape:  (1000, 784)\n",
      "val label shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "num_train = 41000\n",
    "num_val   = 1000\n",
    "\n",
    "indicies = np.arange(num_data)\n",
    "np.random.shuffle(indicies)\n",
    "train_mask = indicies[range(num_train)]\n",
    "val_mask = indicies[range(num_train, num_train + num_val)]\n",
    "\n",
    "train_image = images[train_mask]\n",
    "train_label = labels[train_mask]\n",
    "val_image = images[val_mask]\n",
    "val_label = labels[val_mask]\n",
    "\n",
    "print('train image shape: ', train_image.shape)\n",
    "print('train label shape: ', train_label.shape)\n",
    "print('val image shape: ', val_image.shape)\n",
    "print('val label shape: ', val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "epoch 0:\n",
      "iter: 0, loss: 2.718840, acc: 0.101562\n",
      "iter: 100, loss: 0.066631, acc: 0.968750\n",
      "iter: 200, loss: 0.070996, acc: 0.984375\n",
      "iter: 300, loss: 0.127453, acc: 0.960938\n",
      "val set acc: 0.980000\n",
      "epoch 1:\n",
      "iter: 0, loss: 0.104657, acc: 0.968750\n",
      "iter: 100, loss: 0.012358, acc: 0.992188\n",
      "iter: 200, loss: 0.005361, acc: 1.000000\n",
      "iter: 300, loss: 0.136422, acc: 0.968750\n",
      "val set acc: 0.979000\n",
      "epoch 2:\n",
      "iter: 0, loss: 0.018957, acc: 0.992188\n",
      "iter: 100, loss: 0.025352, acc: 0.992188\n",
      "iter: 200, loss: 0.019976, acc: 0.992188\n",
      "iter: 300, loss: 0.066163, acc: 0.992188\n",
      "val set acc: 0.984000\n",
      "epoch 3:\n",
      "iter: 0, loss: 0.038644, acc: 0.984375\n",
      "iter: 100, loss: 0.009493, acc: 1.000000\n",
      "iter: 200, loss: 0.038203, acc: 0.992188\n",
      "iter: 300, loss: 0.067455, acc: 0.984375\n",
      "val set acc: 0.988000\n",
      "epoch 4:\n",
      "iter: 0, loss: 0.076467, acc: 0.976562\n",
      "iter: 100, loss: 0.064405, acc: 0.992188\n",
      "iter: 200, loss: 0.016621, acc: 0.992188\n",
      "iter: 300, loss: 0.028733, acc: 0.992188\n",
      "val set acc: 0.985000\n",
      "epoch 5:\n",
      "iter: 0, loss: 0.006909, acc: 1.000000\n",
      "iter: 100, loss: 0.000449, acc: 1.000000\n",
      "iter: 200, loss: 0.001158, acc: 1.000000\n",
      "iter: 300, loss: 0.097799, acc: 0.968750\n",
      "val set acc: 0.985000\n",
      "epoch 6:\n",
      "iter: 0, loss: 0.014552, acc: 0.992188\n",
      "iter: 100, loss: 0.047096, acc: 0.992188\n",
      "iter: 200, loss: 0.002414, acc: 1.000000\n",
      "iter: 300, loss: 0.032789, acc: 0.992188\n",
      "val set acc: 0.987000\n",
      "epoch 7:\n",
      "iter: 0, loss: 0.010680, acc: 1.000000\n",
      "iter: 100, loss: 0.003579, acc: 1.000000\n",
      "iter: 200, loss: 0.028258, acc: 0.992188\n",
      "iter: 300, loss: 0.011485, acc: 1.000000\n",
      "val set acc: 0.987000\n",
      "epoch 8:\n",
      "iter: 0, loss: 0.003306, acc: 1.000000\n",
      "iter: 100, loss: 0.005177, acc: 1.000000\n",
      "iter: 200, loss: 0.003595, acc: 1.000000\n",
      "iter: 300, loss: 0.021190, acc: 0.984375\n",
      "val set acc: 0.992000\n",
      "epoch 9:\n",
      "iter: 0, loss: 0.238273, acc: 0.968750\n",
      "iter: 100, loss: 0.010605, acc: 0.992188\n",
      "iter: 200, loss: 0.005257, acc: 1.000000\n",
      "iter: 300, loss: 0.066654, acc: 0.976562\n",
      "val set acc: 0.987000\n",
      "epoch 10:\n",
      "iter: 0, loss: 0.006935, acc: 0.992188\n",
      "iter: 100, loss: 0.001233, acc: 1.000000\n",
      "iter: 200, loss: 0.000901, acc: 1.000000\n",
      "iter: 300, loss: 0.018382, acc: 0.992188\n",
      "val set acc: 0.992000\n",
      "epoch 11:\n",
      "iter: 0, loss: 0.038373, acc: 0.984375\n",
      "iter: 100, loss: 0.005596, acc: 1.000000\n",
      "iter: 200, loss: 0.004962, acc: 1.000000\n",
      "iter: 300, loss: 0.063863, acc: 0.984375\n",
      "val set acc: 0.985000\n",
      "epoch 12:\n",
      "iter: 0, loss: 0.022172, acc: 0.992188\n",
      "iter: 100, loss: 0.000229, acc: 1.000000\n",
      "iter: 200, loss: 0.000257, acc: 1.000000\n",
      "iter: 300, loss: 0.015487, acc: 0.992188\n",
      "val set acc: 0.987000\n",
      "epoch 13:\n",
      "iter: 0, loss: 0.001929, acc: 1.000000\n",
      "iter: 100, loss: 0.008112, acc: 1.000000\n",
      "iter: 200, loss: 0.000958, acc: 1.000000\n",
      "iter: 300, loss: 0.017655, acc: 0.992188\n",
      "val set acc: 0.984000\n",
      "epoch 14:\n",
      "iter: 0, loss: 0.006626, acc: 1.000000\n",
      "iter: 100, loss: 0.001697, acc: 1.000000\n",
      "iter: 200, loss: 0.000326, acc: 1.000000\n",
      "iter: 300, loss: 0.024420, acc: 0.992188\n",
      "val set acc: 0.985000\n",
      "epoch 15:\n",
      "iter: 0, loss: 0.040240, acc: 0.992188\n",
      "iter: 100, loss: 0.069716, acc: 0.992188\n",
      "iter: 200, loss: 0.006076, acc: 1.000000\n",
      "iter: 300, loss: 0.036025, acc: 0.992188\n",
      "val set acc: 0.992000\n",
      "epoch 16:\n",
      "iter: 0, loss: 0.027595, acc: 0.992188\n",
      "iter: 100, loss: 0.000720, acc: 1.000000\n",
      "iter: 200, loss: 0.035199, acc: 0.992188\n",
      "iter: 300, loss: 0.015404, acc: 0.992188\n",
      "val set acc: 0.990000\n",
      "epoch 17:\n",
      "iter: 0, loss: 0.076522, acc: 0.984375\n",
      "iter: 100, loss: 0.008936, acc: 0.992188\n",
      "iter: 200, loss: 0.000580, acc: 1.000000\n",
      "iter: 300, loss: 0.009094, acc: 0.992188\n",
      "val set acc: 0.989000\n",
      "epoch 18:\n",
      "iter: 0, loss: 0.079221, acc: 0.992188\n",
      "iter: 100, loss: 0.000207, acc: 1.000000\n",
      "iter: 200, loss: 0.002551, acc: 1.000000\n",
      "iter: 300, loss: 0.005151, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 19:\n",
      "iter: 0, loss: 0.000305, acc: 1.000000\n",
      "iter: 100, loss: 0.000089, acc: 1.000000\n",
      "iter: 200, loss: 0.000441, acc: 1.000000\n",
      "iter: 300, loss: 0.063440, acc: 0.984375\n",
      "val set acc: 0.992000\n",
      "epoch 20:\n",
      "iter: 0, loss: 0.000141, acc: 1.000000\n",
      "iter: 100, loss: 0.000111, acc: 1.000000\n",
      "iter: 200, loss: 0.000279, acc: 1.000000\n",
      "iter: 300, loss: 0.022689, acc: 0.984375\n",
      "val set acc: 0.991000\n",
      "epoch 21:\n",
      "iter: 0, loss: 0.003769, acc: 1.000000\n",
      "iter: 100, loss: 0.000085, acc: 1.000000\n",
      "iter: 200, loss: 0.027773, acc: 0.976562\n",
      "iter: 300, loss: 0.001267, acc: 1.000000\n",
      "val set acc: 0.990000\n",
      "epoch 22:\n",
      "iter: 0, loss: 0.000092, acc: 1.000000\n",
      "iter: 100, loss: 0.000069, acc: 1.000000\n",
      "iter: 200, loss: 0.000061, acc: 1.000000\n",
      "iter: 300, loss: 0.018141, acc: 0.992188\n",
      "val set acc: 0.992000\n",
      "epoch 23:\n",
      "iter: 0, loss: 0.000665, acc: 1.000000\n",
      "iter: 100, loss: 0.000866, acc: 1.000000\n",
      "iter: 200, loss: 0.002685, acc: 1.000000\n",
      "iter: 300, loss: 0.005442, acc: 1.000000\n",
      "val set acc: 0.987000\n",
      "epoch 24:\n",
      "iter: 0, loss: 0.001171, acc: 1.000000\n",
      "iter: 100, loss: 0.000890, acc: 1.000000\n",
      "iter: 200, loss: 0.000765, acc: 1.000000\n",
      "iter: 300, loss: 0.037108, acc: 0.992188\n",
      "val set acc: 0.992000\n",
      "epoch 25:\n",
      "iter: 0, loss: 0.000276, acc: 1.000000\n",
      "iter: 100, loss: 0.003451, acc: 1.000000\n",
      "iter: 200, loss: 0.010760, acc: 0.992188\n",
      "iter: 300, loss: 0.028001, acc: 0.984375\n",
      "val set acc: 0.994000\n",
      "epoch 26:\n",
      "iter: 0, loss: 0.033548, acc: 0.984375\n",
      "iter: 100, loss: 0.000023, acc: 1.000000\n",
      "iter: 200, loss: 0.006529, acc: 0.992188\n",
      "iter: 300, loss: 0.002979, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 27:\n",
      "iter: 0, loss: 0.005523, acc: 1.000000\n",
      "iter: 100, loss: 0.001837, acc: 1.000000\n",
      "iter: 200, loss: 0.009527, acc: 1.000000\n",
      "iter: 300, loss: 0.027147, acc: 0.992188\n",
      "val set acc: 0.992000\n",
      "epoch 28:\n",
      "iter: 0, loss: 0.014373, acc: 0.992188\n",
      "iter: 100, loss: 0.000220, acc: 1.000000\n",
      "iter: 200, loss: 0.000977, acc: 1.000000\n",
      "iter: 300, loss: 0.003191, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 29:\n",
      "iter: 0, loss: 0.002806, acc: 1.000000\n",
      "iter: 100, loss: 0.000508, acc: 1.000000\n",
      "iter: 200, loss: 0.115394, acc: 0.992188\n",
      "iter: 300, loss: 0.025643, acc: 0.992188\n",
      "val set acc: 0.990000\n",
      "epoch 30:\n",
      "iter: 0, loss: 0.005942, acc: 1.000000\n",
      "iter: 100, loss: 0.001467, acc: 1.000000\n",
      "iter: 200, loss: 0.017845, acc: 0.992188\n",
      "iter: 300, loss: 0.047350, acc: 0.992188\n",
      "val set acc: 0.993000\n",
      "epoch 31:\n",
      "iter: 0, loss: 0.004212, acc: 1.000000\n",
      "iter: 100, loss: 0.000463, acc: 1.000000\n",
      "iter: 200, loss: 0.000029, acc: 1.000000\n",
      "iter: 300, loss: 0.042688, acc: 0.992188\n",
      "val set acc: 0.996000\n",
      "epoch 32:\n",
      "iter: 0, loss: 0.000093, acc: 1.000000\n",
      "iter: 100, loss: 0.000010, acc: 1.000000\n",
      "iter: 200, loss: 0.000043, acc: 1.000000\n",
      "iter: 300, loss: 0.000148, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 33:\n",
      "iter: 0, loss: 0.002449, acc: 1.000000\n",
      "iter: 100, loss: 0.000202, acc: 1.000000\n",
      "iter: 200, loss: 0.000102, acc: 1.000000\n",
      "iter: 300, loss: 0.000097, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 34:\n",
      "iter: 0, loss: 0.000517, acc: 1.000000\n",
      "iter: 100, loss: 0.000014, acc: 1.000000\n",
      "iter: 200, loss: 0.000448, acc: 1.000000\n",
      "iter: 300, loss: 0.001318, acc: 1.000000\n",
      "val set acc: 0.991000\n",
      "epoch 35:\n",
      "iter: 0, loss: 0.000189, acc: 1.000000\n",
      "iter: 100, loss: 0.000008, acc: 1.000000\n",
      "iter: 200, loss: 0.000964, acc: 1.000000\n",
      "iter: 300, loss: 0.005094, acc: 1.000000\n",
      "val set acc: 0.996000\n",
      "epoch 36:\n",
      "iter: 0, loss: 0.000354, acc: 1.000000\n",
      "iter: 100, loss: 0.000059, acc: 1.000000\n",
      "iter: 200, loss: 0.000157, acc: 1.000000\n",
      "iter: 300, loss: 0.021915, acc: 0.992188\n",
      "val set acc: 0.990000\n",
      "epoch 37:\n",
      "iter: 0, loss: 0.023442, acc: 0.992188\n",
      "iter: 100, loss: 0.000106, acc: 1.000000\n",
      "iter: 200, loss: 0.000260, acc: 1.000000\n",
      "iter: 300, loss: 0.005549, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 38:\n",
      "iter: 0, loss: 0.001943, acc: 1.000000\n",
      "iter: 100, loss: 0.000075, acc: 1.000000\n",
      "iter: 200, loss: 0.002740, acc: 1.000000\n",
      "iter: 300, loss: 0.002333, acc: 1.000000\n",
      "val set acc: 0.990000\n",
      "epoch 39:\n",
      "iter: 0, loss: 0.002763, acc: 1.000000\n",
      "iter: 100, loss: 0.000339, acc: 1.000000\n",
      "iter: 200, loss: 0.005940, acc: 0.992188\n",
      "iter: 300, loss: 0.118233, acc: 0.976562\n",
      "val set acc: 0.990000\n",
      "epoch 40:\n",
      "iter: 0, loss: 0.020955, acc: 0.992188\n",
      "iter: 100, loss: 0.000115, acc: 1.000000\n",
      "iter: 200, loss: 0.000036, acc: 1.000000\n",
      "iter: 300, loss: 0.000556, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 41:\n",
      "iter: 0, loss: 0.000492, acc: 1.000000\n",
      "iter: 100, loss: 0.000001, acc: 1.000000\n",
      "iter: 200, loss: 0.000018, acc: 1.000000\n",
      "iter: 300, loss: 0.009736, acc: 0.992188\n",
      "val set acc: 0.986000\n",
      "epoch 42:\n",
      "iter: 0, loss: 0.014151, acc: 0.992188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100, loss: 0.157210, acc: 0.992188\n",
      "iter: 200, loss: 0.000516, acc: 1.000000\n",
      "iter: 300, loss: 0.022986, acc: 0.992188\n",
      "val set acc: 0.990000\n",
      "epoch 43:\n",
      "iter: 0, loss: 0.007272, acc: 0.992188\n",
      "iter: 100, loss: 0.000011, acc: 1.000000\n",
      "iter: 200, loss: 0.000133, acc: 1.000000\n",
      "iter: 300, loss: 0.063036, acc: 0.984375\n",
      "val set acc: 0.989000\n",
      "epoch 44:\n",
      "iter: 0, loss: 0.000719, acc: 1.000000\n",
      "iter: 100, loss: 0.000158, acc: 1.000000\n",
      "iter: 200, loss: 0.000158, acc: 1.000000\n",
      "iter: 300, loss: 0.044854, acc: 0.984375\n",
      "val set acc: 0.989000\n",
      "epoch 45:\n",
      "iter: 0, loss: 0.010791, acc: 0.992188\n",
      "iter: 100, loss: 0.000006, acc: 1.000000\n",
      "iter: 200, loss: 0.004262, acc: 1.000000\n",
      "iter: 300, loss: 0.014211, acc: 0.992188\n",
      "val set acc: 0.993000\n",
      "epoch 46:\n",
      "iter: 0, loss: 0.001556, acc: 1.000000\n",
      "iter: 100, loss: 0.000049, acc: 1.000000\n",
      "iter: 200, loss: 0.000002, acc: 1.000000\n",
      "iter: 300, loss: 0.013620, acc: 0.992188\n",
      "val set acc: 0.993000\n",
      "epoch 47:\n",
      "iter: 0, loss: 0.000071, acc: 1.000000\n",
      "iter: 100, loss: 0.000992, acc: 1.000000\n",
      "iter: 200, loss: 0.000014, acc: 1.000000\n",
      "iter: 300, loss: 0.036399, acc: 0.992188\n",
      "val set acc: 0.991000\n",
      "epoch 48:\n",
      "iter: 0, loss: 0.011924, acc: 0.992188\n",
      "iter: 100, loss: 0.001728, acc: 1.000000\n",
      "iter: 200, loss: 0.000909, acc: 1.000000\n",
      "iter: 300, loss: 0.000156, acc: 1.000000\n",
      "val set acc: 0.994000\n",
      "epoch 49:\n",
      "iter: 0, loss: 0.002125, acc: 1.000000\n",
      "iter: 100, loss: 0.000323, acc: 1.000000\n",
      "iter: 200, loss: 0.000106, acc: 1.000000\n",
      "iter: 300, loss: 0.000044, acc: 1.000000\n",
      "val set acc: 0.991000\n",
      "epoch 50:\n",
      "iter: 0, loss: 0.001538, acc: 1.000000\n",
      "iter: 100, loss: 0.000002, acc: 1.000000\n",
      "iter: 200, loss: 0.000125, acc: 1.000000\n",
      "iter: 300, loss: 0.005145, acc: 1.000000\n",
      "val set acc: 0.991000\n",
      "epoch 51:\n",
      "iter: 0, loss: 0.000736, acc: 1.000000\n",
      "iter: 100, loss: 0.000110, acc: 1.000000\n",
      "iter: 200, loss: 0.000006, acc: 1.000000\n",
      "iter: 300, loss: 0.001377, acc: 1.000000\n",
      "val set acc: 0.986000\n",
      "epoch 52:\n",
      "iter: 0, loss: 0.001147, acc: 1.000000\n",
      "iter: 100, loss: 0.000044, acc: 1.000000\n",
      "iter: 200, loss: 0.001019, acc: 1.000000\n",
      "iter: 300, loss: 0.000013, acc: 1.000000\n",
      "val set acc: 0.989000\n",
      "epoch 53:\n",
      "iter: 0, loss: 0.000735, acc: 1.000000\n",
      "iter: 100, loss: 0.000470, acc: 1.000000\n",
      "iter: 200, loss: 0.000323, acc: 1.000000\n",
      "iter: 300, loss: 0.002892, acc: 1.000000\n",
      "val set acc: 0.994000\n",
      "epoch 54:\n",
      "iter: 0, loss: 0.000089, acc: 1.000000\n",
      "iter: 100, loss: 0.000007, acc: 1.000000\n",
      "iter: 200, loss: 0.000104, acc: 1.000000\n",
      "iter: 300, loss: 0.000145, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 55:\n",
      "iter: 0, loss: 0.000006, acc: 1.000000\n",
      "iter: 100, loss: 0.000001, acc: 1.000000\n",
      "iter: 200, loss: 0.000004, acc: 1.000000\n",
      "iter: 300, loss: 0.000047, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 56:\n",
      "iter: 0, loss: 0.000022, acc: 1.000000\n",
      "iter: 100, loss: 0.000008, acc: 1.000000\n",
      "iter: 200, loss: 0.000415, acc: 1.000000\n",
      "iter: 300, loss: 0.030870, acc: 0.992188\n",
      "val set acc: 0.992000\n",
      "epoch 57:\n",
      "iter: 0, loss: 0.000992, acc: 1.000000\n",
      "iter: 100, loss: 0.000038, acc: 1.000000\n",
      "iter: 200, loss: 0.000044, acc: 1.000000\n",
      "iter: 300, loss: 0.005091, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 58:\n",
      "iter: 0, loss: 0.002886, acc: 1.000000\n",
      "iter: 100, loss: 0.000007, acc: 1.000000\n",
      "iter: 200, loss: 0.000390, acc: 1.000000\n",
      "iter: 300, loss: 0.000034, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 59:\n",
      "iter: 0, loss: 0.011446, acc: 0.992188\n",
      "iter: 100, loss: 0.000017, acc: 1.000000\n",
      "iter: 200, loss: 0.000221, acc: 1.000000\n",
      "iter: 300, loss: 0.033148, acc: 0.992188\n",
      "val set acc: 0.990000\n",
      "epoch 60:\n",
      "iter: 0, loss: 0.000026, acc: 1.000000\n",
      "iter: 100, loss: 0.000059, acc: 1.000000\n",
      "iter: 200, loss: 0.000067, acc: 1.000000\n",
      "iter: 300, loss: 0.000007, acc: 1.000000\n",
      "val set acc: 0.995000\n",
      "epoch 61:\n",
      "iter: 0, loss: 0.000042, acc: 1.000000\n",
      "iter: 100, loss: 0.000025, acc: 1.000000\n",
      "iter: 200, loss: 0.000019, acc: 1.000000\n",
      "iter: 300, loss: 0.001576, acc: 1.000000\n",
      "val set acc: 0.994000\n",
      "epoch 62:\n",
      "iter: 0, loss: 0.000030, acc: 1.000000\n",
      "iter: 100, loss: 0.000002, acc: 1.000000\n",
      "iter: 200, loss: 0.001569, acc: 1.000000\n",
      "iter: 300, loss: 0.000103, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 63:\n",
      "iter: 0, loss: 0.000916, acc: 1.000000\n",
      "iter: 100, loss: 0.002798, acc: 1.000000\n",
      "iter: 200, loss: 0.000452, acc: 1.000000\n",
      "iter: 300, loss: 0.008549, acc: 0.992188\n",
      "val set acc: 0.993000\n",
      "epoch 64:\n",
      "iter: 0, loss: 0.000001, acc: 1.000000\n",
      "iter: 100, loss: 0.000002, acc: 1.000000\n",
      "iter: 200, loss: 0.000008, acc: 1.000000\n",
      "iter: 300, loss: 0.000050, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 65:\n",
      "iter: 0, loss: 0.000001, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000486, acc: 1.000000\n",
      "iter: 300, loss: 0.032554, acc: 0.992188\n",
      "val set acc: 0.989000\n",
      "epoch 66:\n",
      "iter: 0, loss: 0.009765, acc: 0.992188\n",
      "iter: 100, loss: 0.000008, acc: 1.000000\n",
      "iter: 200, loss: 0.081869, acc: 0.992188\n",
      "iter: 300, loss: 0.000075, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 67:\n",
      "iter: 0, loss: 0.000098, acc: 1.000000\n",
      "iter: 100, loss: 0.000001, acc: 1.000000\n",
      "iter: 200, loss: 0.000002, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 68:\n",
      "iter: 0, loss: 0.000012, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000003, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 69:\n",
      "iter: 0, loss: 0.000002, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000001, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 70:\n",
      "iter: 0, loss: 0.000001, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000001, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 71:\n",
      "iter: 0, loss: 0.000001, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000001, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 72:\n",
      "iter: 0, loss: 0.000001, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 73:\n",
      "iter: 0, loss: 0.000001, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 74:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 75:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 76:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 77:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 78:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.992000\n",
      "epoch 79:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 80:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 81:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 82:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 83:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 84:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 85:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 86:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 87:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 88:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 89:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 90:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 91:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 92:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 93:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 94:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 95:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 96:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 97:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 98:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "epoch 99:\n",
      "iter: 0, loss: 0.000000, acc: 1.000000\n",
      "iter: 100, loss: 0.000000, acc: 1.000000\n",
      "iter: 200, loss: 0.000000, acc: 1.000000\n",
      "iter: 300, loss: 0.000000, acc: 1.000000\n",
      "val set acc: 0.993000\n",
      "predicting:\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "val_batch_size = 1000\n",
    "\n",
    "num_test = test_images.shape[0]\n",
    "\n",
    "def model(x):\n",
    "    x = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[2, 2], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)    \n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[2, 2], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True) \n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True)\n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True) \n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu)\n",
    "    x = tf.layers.batch_normalization(x, training=True) \n",
    "\n",
    "    x = tf.contrib.layers.flatten(x)\n",
    "    x = tf.layers.dense(inputs=x, units=4*4*64, activation=tf.nn.relu)\n",
    "    x = tf.layers.dense(inputs=x, units=4*4*64, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(x, 10)\n",
    "    return logits\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "logits = model(X)\n",
    "\n",
    "loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(tf.one_hot(y, 10), logits=logits))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(5e-4).minimize(loss)\n",
    "\n",
    "predictions = tf.equal(tf.argmax(logits, 1), y)\n",
    "acc = tf.reduce_mean(tf.cast(predictions, tf.float32))\n",
    "\n",
    "train_indicies = np.arange(num_train)\n",
    "np.random.shuffle(train_indicies)\n",
    "\n",
    "val_indicies = np.arange(num_val)\n",
    "test_indicies = np.arange(num_test)\n",
    "\n",
    "test_predictions = tf.argmax(logits, 1)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def run_model(sess, show_every):\n",
    "    print('training:')\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch %d:' % epoch)\n",
    "        for iter_i in range(num_train//batch_size):  \n",
    "            start_idx = (iter_i*batch_size)%num_train\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            _loss, _acc, _ = sess.run([loss, acc, train_step], feed_dict={\n",
    "                X: train_image[idx, :], y: train_label[idx]\n",
    "            })\n",
    "            if iter_i % show_every == 0:\n",
    "                print('iter: %d, loss: %f, acc: %f' % (iter_i, _loss, _acc))\n",
    "\n",
    "        #total_correct = []\n",
    "        for iter_i in range(num_val//val_batch_size):\n",
    "            start_idx = (iter_i * val_batch_size) % num_val\n",
    "            idx = val_indicies[start_idx:start_idx+val_batch_size]\n",
    "            val_acc = sess.run(acc, feed_dict={\n",
    "                X:val_image[idx, :], y: val_label[idx]\n",
    "            })\n",
    "            #total_correct = total_correct + val_correct_predictions\n",
    "            print('val set acc: %f'% val_acc)\n",
    "            \n",
    "        save_path = \"../ckpt/epoch%d/model.ckpt\"%epoch\n",
    "        saver.save(sess, save_path)\n",
    "    \n",
    "    print('predicting:')\n",
    "    total_test_predictions = []\n",
    "    test_batch_size = 7000\n",
    "    for test_iter in range(num_test//test_batch_size):\n",
    "        start_test_idx = (test_iter * test_batch_size)%num_test\n",
    "        test_idx = test_indicies[start_test_idx:start_test_idx+test_batch_size]\n",
    "        _test_predictions = sess.run(test_predictions, feed_dict={X:test_images[test_idx, :]})\n",
    "        total_test_predictions = np.concatenate((total_test_predictions,_test_predictions))\n",
    "    return total_test_predictions\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = run_model(sess, show_every=100)\n",
    "    \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../ckpt/epoch31/model.ckpt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-42316f4844e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../ckpt/epoch31/model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission_epoch31.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exec_type, exec_value, exec_tb)\u001b[0m\n\u001b[1;32m   1505\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Session closing due to OpError: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexec_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m     self._default_session_context_manager.__exit__(\n\u001b[0;32m-> 1507\u001b[0;31m         exec_type, exec_value, exec_tb)\n\u001b[0m\u001b[1;32m   1508\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   3967\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3968\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3969\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3970\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enforce_nesting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-42316f4844e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../ckpt/epoch31/model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1560\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1051\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m   1054\u001b[0m                          'graph before calling run().')\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',')\n",
    "    datawriter.writerow(['ImageId', 'Label'])\n",
    "    for i, predict_label in enumerate(result):\n",
    "        datawriter.writerow([i+1, predict_label.astype(np.uint8)])\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(7000, 7010):\n",
    "    display_img(test_images, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
